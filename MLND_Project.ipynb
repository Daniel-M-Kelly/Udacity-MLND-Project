{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company #</th>\n",
       "      <th>Purchase Order</th>\n",
       "      <th>Item</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unit of Measure</th>\n",
       "      <th>Units</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Cost Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-001</td>\n",
       "      <td>1</td>\n",
       "      <td>Paragon Electrical Installations Ltd.</td>\n",
       "      <td>Additional smoke detector/re-verification</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>26-20-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-002</td>\n",
       "      <td>1</td>\n",
       "      <td>Accurate Aluminum Ltd</td>\n",
       "      <td>S&amp;I railing as per quote Aug. 13  2015</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>05-52-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-003</td>\n",
       "      <td>1</td>\n",
       "      <td>Dura Productions</td>\n",
       "      <td>S&amp;I metal ramp</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>05-52-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-004</td>\n",
       "      <td>1</td>\n",
       "      <td>Friesen Floors &amp; Window Fashions Ltd</td>\n",
       "      <td>S&amp;I hardwood flooring for enclosed balcony area</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>09-64-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1209-1-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Alba Painting Ltd.</td>\n",
       "      <td>Painting of two offices</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>09-91-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company # Purchase Order  Item                                 Vendor  \\\n",
       "0          8       1200-001     1  Paragon Electrical Installations Ltd.   \n",
       "1          8       1200-002     1                  Accurate Aluminum Ltd   \n",
       "2          8       1200-003     1                       Dura Productions   \n",
       "3          8       1200-004     1   Friesen Floors & Window Fashions Ltd   \n",
       "4          8      1209-1-01     1                     Alba Painting Ltd.   \n",
       "\n",
       "                                       Description Unit of Measure Units  \\\n",
       "0        Additional smoke detector/re-verification              LS     0   \n",
       "1           S&I railing as per quote Aug. 13  2015              LS     0   \n",
       "2                                   S&I metal ramp              LS     0   \n",
       "3  S&I hardwood flooring for enclosed balcony area              LS     0   \n",
       "4                          Painting of two offices              LS     0   \n",
       "\n",
       "   Unit Cost    Cost Cost Code  \n",
       "0        0.0  1444.0  26-20-20  \n",
       "1        0.0   500.0  05-52-20  \n",
       "2        0.0   795.0  05-52-20  \n",
       "3        0.0  2314.0  09-64-33  \n",
       "4        0.0   900.0  09-91-40  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data from CSV files.\n",
    "df = pd.read_csv('raw_data/PO_Dataset.csv')\n",
    "name_mapping = pd.read_csv('clean_data/Clean_Code_Master_list.csv')\n",
    "\n",
    "#Check data was read as expected\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Convert the Units column to float\n",
    "df['Units'] = pd.to_numeric(df['Units'], errors='coerce').fillna(0)\n",
    "df['Units'] = df['Units'].astype('float64')\n",
    "\n",
    "#Drop lines with null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Read in Master list of valid cost codes\n",
    "df_ml = pd.read_csv('raw_data/Code_Master_list.csv')\n",
    "\n",
    "#Drop rows where the cost code is not in the master list\n",
    "df = df[df['Cost Code'].isin(df_ml['Cost Code'])].dropna()\n",
    "\n",
    "#Create a new dataframe that takes only the 90th quartile of data from the 3 numerical columns.\n",
    "df_90 = df[df['Cost'] < df['Cost'].quantile(.90)]\n",
    "df_90 = df_90[df_90['Units'] < df_90['Units'].quantile(.90)]\n",
    "df_90 = df_90[df_90['Unit Cost'] < df_90['Unit Cost'].quantile(.90)]\n",
    "\n",
    "# It's a good practice to scale numerical data\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() \n",
    "numerical = ['Units','Unit Cost','Cost']\n",
    "\n",
    "df_90[numerical] = scaler.fit_transform(df_90[numerical])\n",
    "\n",
    "# When splitting for training and testing later, we'll need a minimum of 2 examples of each cost code.\n",
    "# Assign cost code to a variable\n",
    "df_count = df_90['Cost Code'].value_counts()\n",
    "\n",
    "#New dataframe only includes lines with cost codes with a count of 10 or greater\n",
    "df_90 = df_90[~df_90['Cost Code'].isin(df_count[df_count < 10].index)]\n",
    "\n",
    "\n",
    "#One Hot Encode categorical features\n",
    "categorical = ['Vendor', 'Unit of Measure']\n",
    "df_90 = pd.get_dummies(df_90, columns = categorical )\n",
    "\n",
    "#Numerically encode cost codes.\n",
    "le = LabelEncoder()\n",
    "cost_code = df_90['Cost Code']\n",
    "df_90['Cost Code Encoded'] = le.fit_transform(cost_code)\n",
    "\n",
    "#drop features I won't be using\n",
    "df_90 = df_90.drop(['Company #','Purchase Order', 'Item'], axis = 1)\n",
    "\n",
    "\n",
    "df = df_90\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Separate the target variable from the features\n",
    "cost_codes = df['Cost Code Encoded']\n",
    "features = df.drop(['Cost Code','Cost Code Encoded'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn train test split to split the data into training and testing sets. \n",
    "#Testing set is 20% of total dataset size.\n",
    "#Stratify the data so we don't introduce bias in the sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    cost_codes,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = cost_codes\n",
    "                                                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22349, 418)\n",
      "(22349,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Units</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Vendor_1110438 B.C. Ltd</th>\n",
       "      <th>Vendor_4s Scaffolding</th>\n",
       "      <th>Vendor_596143 BC LTD DBA AVANTE 2000</th>\n",
       "      <th>Vendor_7 Star Security Services Inc</th>\n",
       "      <th>Vendor_A &amp; A Testing Ltd.</th>\n",
       "      <th>Vendor_A Plus Cleaning and Janitorial Ltd.</th>\n",
       "      <th>...</th>\n",
       "      <th>Unit of Measure_WKS</th>\n",
       "      <th>Unit of Measure_kg</th>\n",
       "      <th>Unit of Measure_km</th>\n",
       "      <th>Unit of Measure_kw</th>\n",
       "      <th>Unit of Measure_l</th>\n",
       "      <th>Unit of Measure_m</th>\n",
       "      <th>Unit of Measure_m3</th>\n",
       "      <th>Unit of Measure_m3</th>\n",
       "      <th>Unit of Measure_mL</th>\n",
       "      <th>Unit of Measure_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36104</th>\n",
       "      <td>Fuel Cost Recover</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.979801</td>\n",
       "      <td>0.908284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12262</th>\n",
       "      <td>fuel</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.987592</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31408</th>\n",
       "      <td>3M Disposable Particulate Respirator</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.908996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>GAS</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.979483</td>\n",
       "      <td>0.908990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>Permit</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.979224</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Description     Units  Unit Cost      Cost  \\\n",
       "36104                     Fuel Cost Recover  0.998974   0.979801  0.908284   \n",
       "12262                                  fuel  0.998974   0.987592  0.911008   \n",
       "31408  3M Disposable Particulate Respirator  0.998974   0.981839  0.908996   \n",
       "1286                                    GAS  0.999274   0.979483  0.908990   \n",
       "4861                                 Permit  0.998941   0.979224  0.912118   \n",
       "\n",
       "       Vendor_1110438 B.C. Ltd  Vendor_4s Scaffolding  \\\n",
       "36104                        0                      0   \n",
       "12262                        0                      0   \n",
       "31408                        0                      0   \n",
       "1286                         0                      0   \n",
       "4861                         0                      0   \n",
       "\n",
       "       Vendor_596143 BC LTD DBA AVANTE 2000  \\\n",
       "36104                                     0   \n",
       "12262                                     0   \n",
       "31408                                     0   \n",
       "1286                                      0   \n",
       "4861                                      0   \n",
       "\n",
       "       Vendor_7 Star Security Services Inc  Vendor_A & A Testing Ltd.  \\\n",
       "36104                                    0                          0   \n",
       "12262                                    0                          0   \n",
       "31408                                    0                          0   \n",
       "1286                                     0                          0   \n",
       "4861                                     0                          0   \n",
       "\n",
       "       Vendor_A Plus Cleaning and Janitorial Ltd.        ...          \\\n",
       "36104                                           0        ...           \n",
       "12262                                           0        ...           \n",
       "31408                                           0        ...           \n",
       "1286                                            0        ...           \n",
       "4861                                            0        ...           \n",
       "\n",
       "       Unit of Measure_WKS  Unit of Measure_kg  Unit of Measure_km  \\\n",
       "36104                    0                   0                   0   \n",
       "12262                    0                   0                   0   \n",
       "31408                    0                   0                   0   \n",
       "1286                     0                   0                   0   \n",
       "4861                     0                   0                   0   \n",
       "\n",
       "       Unit of Measure_kw  Unit of Measure_l  Unit of Measure_m  \\\n",
       "36104                   0                  0                  0   \n",
       "12262                   0                  0                  0   \n",
       "31408                   0                  0                  0   \n",
       "1286                    0                  1                  0   \n",
       "4861                    0                  0                  0   \n",
       "\n",
       "       Unit of Measure_m3  Unit of Measure_m3   Unit of Measure_mL  \\\n",
       "36104                   0                    0                   0   \n",
       "12262                   0                    0                   0   \n",
       "31408                   0                    0                   0   \n",
       "1286                    0                    0                   0   \n",
       "4861                    0                    0                   0   \n",
       "\n",
       "       Unit of Measure_t  \n",
       "36104                  0  \n",
       "12262                  0  \n",
       "31408                  0  \n",
       "1286                   0  \n",
       "4861                   0  \n",
       "\n",
       "[5 rows x 418 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm the number of samples in X and y training data are the same\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split X_train and X_test text Descriptions for use in sepearate model.\n",
    "X_train_desc = X_train['Description'].copy()\n",
    "X_train = X_train.drop('Description', axis=1)\n",
    "\n",
    "X_test_desc = X_test['Description'].copy()\n",
    "X_test = X_test.drop('Description', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    8.4s remaining:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.4226156610112741\n",
      "{'clf__alpha': 0.0001, 'clf__loss': 'hinge', 'clf__max_iter': 20, 'clf__penalty': 'l2', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      " Test output\n",
      "accuracy 47.0472%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.57      0.95      0.71       112\n",
      "           2       0.39      0.88      0.54         8\n",
      "           3       0.76      0.76      0.76        29\n",
      "           4       0.85      0.89      0.87        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.80      0.17      0.29        23\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.47      0.30      0.37        46\n",
      "           9       0.68      0.71      0.69       156\n",
      "          10       0.48      0.55      0.52        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.23      0.75      0.35        12\n",
      "          13       0.40      0.24      0.30        51\n",
      "          14       0.64      0.77      0.70       215\n",
      "          15       0.45      0.26      0.33       110\n",
      "          16       0.79      0.69      0.73        16\n",
      "          17       0.50      0.07      0.12        15\n",
      "          18       0.80      0.57      0.67         7\n",
      "          19       0.67      0.49      0.57        61\n",
      "          20       0.45      0.54      0.49       534\n",
      "          21       0.33      0.07      0.12        14\n",
      "          22       0.42      0.33      0.37       210\n",
      "          23       0.86      0.95      0.90        19\n",
      "          24       0.59      0.44      0.51        45\n",
      "          25       0.08      0.09      0.09        11\n",
      "          26       0.50      0.25      0.33         8\n",
      "          27       0.50      0.20      0.29        10\n",
      "          28       0.42      0.40      0.41        25\n",
      "          29       0.14      0.14      0.14         7\n",
      "          30       0.25      0.50      0.33         4\n",
      "          31       0.51      0.54      0.53        46\n",
      "          32       0.52      0.35      0.42        31\n",
      "          33       0.20      0.16      0.18        19\n",
      "          34       1.00      0.33      0.50         3\n",
      "          35       0.60      0.38      0.46        32\n",
      "          36       0.50      0.12      0.20        16\n",
      "          37       0.56      0.71      0.63         7\n",
      "          38       0.29      0.18      0.22        67\n",
      "          39       0.16      0.08      0.11        36\n",
      "          40       0.58      0.59      0.58        32\n",
      "          41       0.57      0.50      0.53        16\n",
      "          42       0.61      0.73      0.66       210\n",
      "          43       0.65      0.58      0.61        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.20      0.17      0.18         6\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.19      0.64      0.29        25\n",
      "          49       0.45      0.38      0.41        91\n",
      "          50       0.50      0.50      0.50         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.63      0.54      0.58       181\n",
      "          53       0.62      0.56      0.59         9\n",
      "          54       0.36      0.14      0.21       159\n",
      "          55       0.45      0.38      0.41       536\n",
      "          56       0.64      0.18      0.28       202\n",
      "          57       0.43      0.71      0.54       829\n",
      "          58       0.29      0.16      0.21       471\n",
      "          59       0.39      0.45      0.42        66\n",
      "          60       0.50      0.08      0.14        24\n",
      "          61       0.33      0.11      0.17         9\n",
      "          62       0.27      0.08      0.12        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.62      1.00      0.76        13\n",
      "          67       0.61      0.73      0.67        15\n",
      "          68       0.57      0.50      0.53        16\n",
      "          69       1.00      0.50      0.67         2\n",
      "          70       0.76      0.84      0.80        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.21      0.44      0.29        68\n",
      "          73       1.00      0.06      0.11        18\n",
      "          74       0.25      0.11      0.15        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.40      0.40      0.40         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       1.00      0.33      0.50         3\n",
      "          80       0.25      0.25      0.25         4\n",
      "          81       0.13      0.42      0.20        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.75      0.75      0.75         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.75      0.60      0.67         5\n",
      "          86       0.64      0.69      0.67        13\n",
      "          87       0.60      0.50      0.55         6\n",
      "          88       0.29      0.33      0.31         6\n",
      "          89       1.00      0.25      0.40         4\n",
      "          90       0.50      0.40      0.44         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.67      0.67      0.67         6\n",
      "          94       0.50      0.50      0.50         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.60      0.60      0.60         5\n",
      "          98       0.50      0.25      0.33         4\n",
      "          99       0.00      0.00      0.00         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       1.00      0.33      0.50         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.55      0.57      0.56       102\n",
      "         104       0.63      0.41      0.50        41\n",
      "         105       0.58      0.48      0.52        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.33      0.12      0.18         8\n",
      "         108       1.00      0.33      0.50         3\n",
      "         109       0.50      0.75      0.60         8\n",
      "         110       0.14      0.11      0.12         9\n",
      "         111       0.60      0.27      0.37        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       0.50      0.20      0.29         5\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      5588\n",
      "   macro avg       0.46      0.37      0.38      5588\n",
      "weighted avg       0.47      0.47      0.45      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/SGDC_CV.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c5e5f994b58b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m#Save model so we can load it without needing to train it later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGDC_CV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/SGDC_CV.sav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/SGDC_CV.sav'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Create a pipeline for vectorizing the description text, calculating the tfidf value, and training the classifer\n",
    "\n",
    "SGDC_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(random_state=42, tol = 1e-3)),\n",
    "               ])\n",
    "\n",
    "#Configure the parameters to iterate through for the vectorizer, tfidf, and the classifer\n",
    "parameters = {\n",
    "    #'clf__loss':['hinge','log'],\n",
    "    #'clf__penalty':['l1','l2'],\n",
    "    #'clf__alpha':[1e-3,1e-4],\n",
    "    #'clf__max_iter':[15,20,25],\n",
    "    #'vect__ngram_range':[(1,1),(1,2)],\n",
    "    #'tfidf__use_idf':[True,False]\n",
    "    'clf__loss':['hinge'],\n",
    "    'clf__penalty':['l2'],\n",
    "    'clf__alpha':[1e-4],\n",
    "    'clf__max_iter':[20],\n",
    "    'vect__ngram_range':[(1,2)],\n",
    "    'tfidf__use_idf':[True]\n",
    "}\n",
    "\n",
    "\n",
    "#Configure Gridsearch cross validation score using f1_weighted since that's how we'll judge the best model\n",
    "SGDC_CV = GridSearchCV(SGDC_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "#Execute the gridsearch and fit the model\n",
    "SGDC_CV.fit(X_train_desc, y_train)\n",
    "\n",
    "#Print the best parameters and score \n",
    "print('Best score and parameter combination = ')\n",
    "print(SGDC_CV.best_score_)    \n",
    "print(SGDC_CV.best_params_) \n",
    "\n",
    "#Predict the test set\n",
    "SGDC_y_pred = SGDC_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(SGDC_y_pred, y_test)))\n",
    "print(classification_report(y_test, SGDC_y_pred))\n",
    "\n",
    "#Save model so we can load it without needing to train it later\n",
    "pickle.dump(SGDC_CV, open('models/SGDC_CV.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   10.8s remaining:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   18.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.4489943184268057\n",
      "{'clf__C': 20, 'clf__max_iter': 100, 'clf__solver': 'saga', 'clf__tol': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      " Test output\n",
      "accuracy 48.6578%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.96      0.96      0.96       112\n",
      "           2       0.71      0.62      0.67         8\n",
      "           3       0.83      0.69      0.75        29\n",
      "           4       1.00      0.84      0.91        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.44      0.35      0.39        23\n",
      "           7       0.80      0.80      0.80         5\n",
      "           8       0.44      0.35      0.39        46\n",
      "           9       0.60      0.83      0.70       156\n",
      "          10       0.52      0.41      0.46        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.45      0.42      0.43        12\n",
      "          13       0.33      0.22      0.26        51\n",
      "          14       0.64      0.76      0.70       215\n",
      "          15       0.43      0.26      0.33       110\n",
      "          16       0.85      0.69      0.76        16\n",
      "          17       0.20      0.07      0.10        15\n",
      "          18       1.00      0.57      0.73         7\n",
      "          19       0.66      0.51      0.57        61\n",
      "          20       0.37      0.66      0.47       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.39      0.38      0.38       210\n",
      "          23       0.89      0.89      0.89        19\n",
      "          24       0.47      0.31      0.37        45\n",
      "          25       0.12      0.09      0.11        11\n",
      "          26       0.43      0.38      0.40         8\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.36      0.36      0.36        25\n",
      "          29       0.22      0.29      0.25         7\n",
      "          30       0.43      0.75      0.55         4\n",
      "          31       0.59      0.48      0.53        46\n",
      "          32       0.40      0.26      0.31        31\n",
      "          33       0.50      0.21      0.30        19\n",
      "          34       0.25      0.33      0.29         3\n",
      "          35       0.71      0.38      0.49        32\n",
      "          36       0.29      0.12      0.17        16\n",
      "          37       0.40      0.29      0.33         7\n",
      "          38       0.24      0.18      0.21        67\n",
      "          39       0.33      0.17      0.22        36\n",
      "          40       0.53      0.53      0.53        32\n",
      "          41       0.70      0.44      0.54        16\n",
      "          42       0.62      0.70      0.65       210\n",
      "          43       0.63      0.45      0.53        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      0.17      0.25         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.69      0.36      0.47        25\n",
      "          49       0.60      0.43      0.50        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.70      0.51      0.59       181\n",
      "          53       0.67      0.44      0.53         9\n",
      "          54       0.70      0.19      0.30       159\n",
      "          55       0.42      0.52      0.46       536\n",
      "          56       0.80      0.20      0.32       202\n",
      "          57       0.44      0.76      0.56       829\n",
      "          58       0.37      0.11      0.16       471\n",
      "          59       0.56      0.21      0.31        66\n",
      "          60       0.20      0.04      0.07        24\n",
      "          61       0.00      0.00      0.00         9\n",
      "          62       0.29      0.05      0.09        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.47      0.69      0.56        13\n",
      "          67       0.80      0.80      0.80        15\n",
      "          68       0.60      0.38      0.46        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.86      0.63      0.73        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.55      0.34      0.42        68\n",
      "          73       0.55      0.33      0.41        18\n",
      "          74       0.40      0.11      0.17        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.50      0.40      0.44         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       1.00      0.17      0.29        12\n",
      "          82       1.00      0.50      0.67         2\n",
      "          83       0.42      0.62      0.50         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.85      0.85      0.85        13\n",
      "          87       0.33      0.17      0.22         6\n",
      "          88       1.00      0.83      0.91         6\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.00      0.00      0.00         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.75      0.50      0.60         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.50      0.40      0.44         5\n",
      "          98       0.00      0.00      0.00         4\n",
      "          99       1.00      0.25      0.40         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.67      0.33      0.44         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.50      0.55      0.52       102\n",
      "         104       0.57      0.39      0.46        41\n",
      "         105       0.40      0.26      0.32        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.25      0.12      0.17         8\n",
      "         108       0.50      0.33      0.40         3\n",
      "         109       0.71      0.62      0.67         8\n",
      "         110       0.50      0.11      0.18         9\n",
      "         111       0.60      0.27      0.37        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      5588\n",
      "   macro avg       0.43      0.32      0.35      5588\n",
      "weighted avg       0.50      0.49      0.46      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Try a Logistic Regression model to compare to the SGDC model for text classificaton\n",
    "\n",
    "LR_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(random_state=42,multi_class='multinomial')),\n",
    "               ])\n",
    "parameters = {\n",
    "    #'clf__C':[10,20],\n",
    "    #'clf__solver':['saga','lbfgs'],\n",
    "    #'clf__max_iter':[100,200],\n",
    "    #'clf__tol': [1e-2,1e-3],\n",
    "    #'vect__ngram_range':[(1,1),(1,2)],\n",
    "    #'tfidf__use_idf':[True,False]\n",
    "    'clf__C':[20],\n",
    "    'clf__solver':['saga'],\n",
    "    'clf__max_iter':[100],\n",
    "    'clf__tol': [1e-3],\n",
    "    'vect__ngram_range':[(1,2)],\n",
    "    'tfidf__use_idf':[True]\n",
    "}\n",
    "\n",
    "LR_CV = GridSearchCV(LR_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose=5)\n",
    "\n",
    "LR_CV.fit(X_train_desc, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(LR_CV.best_score_)    \n",
    "print(LR_CV.best_params_) \n",
    "\n",
    "\n",
    "LR_y_pred = LR_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(LR_y_pred, y_test)))\n",
    "print(classification_report(y_test, LR_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(LR_CV, open('models/LR_CV.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.43998618162524655\n",
      "{'clf__alpha': 0.0001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      " Test output\n",
      "accuracy 46.5104%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       0.85      0.88      0.86       112\n",
      "           2       0.67      0.75      0.71         8\n",
      "           3       0.73      0.66      0.69        29\n",
      "           4       0.90      0.95      0.92        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.50      0.57      0.53        23\n",
      "           7       0.40      0.80      0.53         5\n",
      "           8       0.35      0.35      0.35        46\n",
      "           9       0.61      0.78      0.69       156\n",
      "          10       0.31      0.59      0.40        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.60      0.75      0.67        12\n",
      "          13       0.37      0.20      0.26        51\n",
      "          14       0.67      0.73      0.70       215\n",
      "          15       0.41      0.28      0.33       110\n",
      "          16       0.85      0.69      0.76        16\n",
      "          17       0.12      0.07      0.09        15\n",
      "          18       1.00      0.71      0.83         7\n",
      "          19       0.60      0.44      0.51        61\n",
      "          20       0.40      0.50      0.44       534\n",
      "          21       0.20      0.29      0.24        14\n",
      "          22       0.42      0.35      0.38       210\n",
      "          23       0.95      0.95      0.95        19\n",
      "          24       0.69      0.40      0.51        45\n",
      "          25       0.12      0.18      0.15        11\n",
      "          26       0.27      0.38      0.32         8\n",
      "          27       0.20      0.20      0.20        10\n",
      "          28       0.41      0.52      0.46        25\n",
      "          29       0.20      0.14      0.17         7\n",
      "          30       0.18      0.50      0.27         4\n",
      "          31       0.53      0.54      0.54        46\n",
      "          32       0.39      0.23      0.29        31\n",
      "          33       0.17      0.11      0.13        19\n",
      "          34       0.25      0.33      0.29         3\n",
      "          35       0.48      0.38      0.42        32\n",
      "          36       0.45      0.31      0.37        16\n",
      "          37       0.44      0.57      0.50         7\n",
      "          38       0.30      0.19      0.23        67\n",
      "          39       0.38      0.25      0.30        36\n",
      "          40       0.62      0.62      0.62        32\n",
      "          41       0.60      0.56      0.58        16\n",
      "          42       0.62      0.61      0.62       210\n",
      "          43       0.65      0.66      0.65        53\n",
      "          44       0.33      0.50      0.40         2\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.60      0.48      0.53        25\n",
      "          49       0.68      0.33      0.44        91\n",
      "          50       0.25      0.50      0.33         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.68      0.48      0.56       181\n",
      "          53       0.71      0.56      0.63         9\n",
      "          54       0.71      0.11      0.19       159\n",
      "          55       0.44      0.43      0.44       536\n",
      "          56       0.58      0.18      0.28       202\n",
      "          57       0.40      0.64      0.49       829\n",
      "          58       0.39      0.23      0.29       471\n",
      "          59       0.23      0.53      0.33        66\n",
      "          60       0.21      0.12      0.16        24\n",
      "          61       0.40      0.22      0.29         9\n",
      "          62       0.17      0.16      0.16        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       1.00      0.50      0.67         2\n",
      "          66       0.68      1.00      0.81        13\n",
      "          67       0.74      0.93      0.82        15\n",
      "          68       0.44      0.50      0.47        16\n",
      "          69       0.50      0.50      0.50         2\n",
      "          70       0.59      0.68      0.63        19\n",
      "          71       0.50      0.50      0.50         2\n",
      "          72       0.48      0.40      0.44        68\n",
      "          73       0.62      0.28      0.38        18\n",
      "          74       0.40      0.32      0.35        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       1.00      0.20      0.33         5\n",
      "          77       0.67      0.40      0.50         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       1.00      0.33      0.50         3\n",
      "          80       0.17      0.25      0.20         4\n",
      "          81       0.33      0.25      0.29        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.43      0.38      0.40         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.80      0.80      0.80         5\n",
      "          86       0.69      0.69      0.69        13\n",
      "          87       0.25      0.17      0.20         6\n",
      "          88       0.57      0.67      0.62         6\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.38      0.60      0.46         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.44      0.67      0.53         6\n",
      "          94       0.25      0.50      0.33         2\n",
      "          95       0.33      0.50      0.40         2\n",
      "          96       1.00      0.50      0.67         2\n",
      "          97       0.29      0.80      0.42         5\n",
      "          98       0.67      0.50      0.57         4\n",
      "          99       0.25      0.25      0.25         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       0.60      0.50      0.55         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.64      0.54      0.59       102\n",
      "         104       0.57      0.32      0.41        41\n",
      "         105       0.34      0.52      0.41        23\n",
      "         106       1.00      0.67      0.80         3\n",
      "         107       0.14      0.12      0.13         8\n",
      "         108       0.50      0.33      0.40         3\n",
      "         109       0.67      0.75      0.71         8\n",
      "         110       0.27      0.44      0.33         9\n",
      "         111       0.46      0.27      0.34        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.25      0.33      0.29         3\n",
      "         114       0.50      0.20      0.29         5\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      5588\n",
      "   macro avg       0.45      0.41      0.41      5588\n",
      "weighted avg       0.49      0.47      0.45      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Create a pipeline for vectorizing the description text, calculating the tfidf value, and training the classifer\n",
    "\n",
    "MNB_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB()),\n",
    "               ])\n",
    "\n",
    "#Configure the parameters to iterate through for the vectorizer, tfidf, and the classifer\n",
    "parameters = {\n",
    "    'clf__alpha':[1e-4, 1e-5],\n",
    "    'vect__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'tfidf__use_idf':[True,False]\n",
    "}\n",
    "\n",
    "\n",
    "#Configure Gridsearch cross validation score using f1_weighted since that's how we'll judge the best model\n",
    "MNB_CV = GridSearchCV(MNB_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "#Execute the gridsearch and fit the model\n",
    "MNB_CV.fit(X_train_desc, y_train)\n",
    "\n",
    "#Print the best parameters and score \n",
    "print('Best score and parameter combination = ')\n",
    "print(MNB_CV.best_score_)    \n",
    "print(MNB_CV.best_params_) \n",
    "\n",
    "#Predict the test set\n",
    "MNB_y_pred = MNB_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(MNB_y_pred, y_test)))\n",
    "print(classification_report(y_test, MNB_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Logistic Regression model had the best accuracy, load the model saved to file\n",
    "LR_CV = pickle.load(open('models/LR_CV.sav', 'rb'))\n",
    "\n",
    "\n",
    "# Append its prediction to the training and testing datasets to create a new feature\n",
    "X_train['Desc Pred'] = LR_CV.predict(X_train_desc)\n",
    "X_test['Desc Pred'] = LR_CV.predict(X_test_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  1.2min remaining:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.5652254018459508\n",
      "{'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 700}\n",
      "\n",
      " Test output\n",
      "accuracy 52.9528%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.89      0.96      0.93       112\n",
      "           2       1.00      0.62      0.77         8\n",
      "           3       0.90      0.62      0.73        29\n",
      "           4       1.00      0.79      0.88        19\n",
      "           5       0.80      0.80      0.80         5\n",
      "           6       1.00      0.04      0.08        23\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.59      0.35      0.44        46\n",
      "           9       0.69      0.76      0.72       156\n",
      "          10       0.75      0.31      0.44        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.71      0.42      0.53        12\n",
      "          13       0.58      0.22      0.31        51\n",
      "          14       0.73      0.84      0.78       215\n",
      "          15       0.62      0.34      0.44       110\n",
      "          16       1.00      1.00      1.00        16\n",
      "          17       1.00      0.07      0.12        15\n",
      "          18       1.00      0.71      0.83         7\n",
      "          19       0.94      0.49      0.65        61\n",
      "          20       0.38      0.78      0.51       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.39      0.46      0.42       210\n",
      "          23       0.77      0.89      0.83        19\n",
      "          24       0.59      0.29      0.39        45\n",
      "          25       0.29      0.18      0.22        11\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.25      0.10      0.14        10\n",
      "          28       0.50      0.40      0.44        25\n",
      "          29       0.67      0.29      0.40         7\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.88      0.61      0.72        46\n",
      "          32       0.53      0.26      0.35        31\n",
      "          33       1.00      0.21      0.35        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.64      0.22      0.33        32\n",
      "          36       0.20      0.12      0.15        16\n",
      "          37       1.00      0.43      0.60         7\n",
      "          38       0.42      0.15      0.22        67\n",
      "          39       0.18      0.06      0.09        36\n",
      "          40       0.89      0.78      0.83        32\n",
      "          41       1.00      0.31      0.48        16\n",
      "          42       0.55      0.71      0.62       210\n",
      "          43       0.73      0.42      0.53        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.75      0.60      0.67        25\n",
      "          49       0.69      0.51      0.58        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.92      0.54      0.68       181\n",
      "          53       0.50      0.22      0.31         9\n",
      "          54       0.68      0.33      0.45       159\n",
      "          55       0.48      0.53      0.51       536\n",
      "          56       0.69      0.22      0.34       202\n",
      "          57       0.46      0.78      0.58       829\n",
      "          58       0.50      0.24      0.32       471\n",
      "          59       0.71      0.26      0.38        66\n",
      "          60       1.00      0.04      0.08        24\n",
      "          61       1.00      0.22      0.36         9\n",
      "          62       0.00      0.00      0.00        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.50      0.50      0.50         2\n",
      "          66       0.67      0.77      0.71        13\n",
      "          67       0.88      0.93      0.90        15\n",
      "          68       0.29      0.12      0.17        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.65      0.58      0.61        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.44      0.37      0.40        68\n",
      "          73       0.56      0.28      0.37        18\n",
      "          74       0.17      0.05      0.08        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       1.00      0.33      0.50         3\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.75      0.50      0.60        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       1.00      0.75      0.86         8\n",
      "          84       0.50      0.33      0.40         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       1.00      0.85      0.92        13\n",
      "          87       1.00      0.17      0.29         6\n",
      "          88       1.00      0.83      0.91         6\n",
      "          89       1.00      0.25      0.40         4\n",
      "          90       1.00      0.40      0.57         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.67      0.80         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       1.00      0.40      0.57         5\n",
      "          98       0.00      0.00      0.00         4\n",
      "          99       1.00      0.25      0.40         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       1.00      0.17      0.29         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.54      0.57      0.56       102\n",
      "         104       0.79      0.46      0.58        41\n",
      "         105       0.54      0.61      0.57        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       1.00      0.50      0.67         8\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       0.71      0.62      0.67         8\n",
      "         110       1.00      0.22      0.36         9\n",
      "         111       0.67      0.27      0.39        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      5588\n",
      "   macro avg       0.53      0.33      0.38      5588\n",
      "weighted avg       0.56      0.53      0.50      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Try a random forest ensemble classifier to evaluate the numeric features plus the predicted feature\n",
    "RF_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "parameters = {'max_depth': [100],\n",
    "              'min_samples_split': [2],\n",
    "              'min_samples_leaf': [2],\n",
    "              'n_estimators': [700]\n",
    "             }\n",
    "\n",
    "RF_CV = GridSearchCV(RF_clf, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "RF_CV.fit(X_train, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(RF_CV.best_score_)    \n",
    "print(RF_CV.best_params_) \n",
    "\n",
    "\n",
    "RF_y_pred = RF_CV.predict(X_test)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(RF_y_pred, y_test)))\n",
    "print(classification_report(y_test, RF_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(RF_CV, open('models/RF_CV.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {}\n",
    "\n",
    "def rec_scores(name, y_pred):\n",
    "\n",
    "    model_scores[name] = classification_report(y_test, y_pred, output_dict=True)['weighted avg']\n",
    "    model_scores[name]['accuracy'] = accuracy_score(y_pred, y_test)\n",
    "    model_scores[name].pop('support',None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rec_scores('RF', RF_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1a44e4e0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What do the feature importances look like?\n",
    "(pd.Series(RF_CV.best_estimator_.feature_importances_, index=X_train.columns).nlargest(4).plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   38.2s remaining:   57.3s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.6580369783557458\n",
      "{'n_neighbors': 10, 'weights': 'distance'}\n",
      "accuracy 0.5159269863994274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.96      0.96      0.96       112\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.88      0.72      0.79        29\n",
      "           4       0.94      0.84      0.89        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.47      0.35      0.40        23\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       0.42      0.41      0.42        46\n",
      "           9       0.73      0.78      0.76       156\n",
      "          10       0.47      0.55      0.51        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.45      0.42      0.43        12\n",
      "          13       0.37      0.27      0.31        51\n",
      "          14       0.67      0.78      0.72       215\n",
      "          15       0.44      0.36      0.40       110\n",
      "          16       0.85      0.69      0.76        16\n",
      "          17       0.17      0.07      0.10        15\n",
      "          18       1.00      0.57      0.73         7\n",
      "          19       0.66      0.57      0.61        61\n",
      "          20       0.44      0.59      0.50       534\n",
      "          21       0.17      0.07      0.10        14\n",
      "          22       0.41      0.47      0.44       210\n",
      "          23       0.74      0.89      0.81        19\n",
      "          24       0.41      0.36      0.38        45\n",
      "          25       0.30      0.27      0.29        11\n",
      "          26       0.43      0.38      0.40         8\n",
      "          27       0.20      0.10      0.13        10\n",
      "          28       0.32      0.40      0.36        25\n",
      "          29       0.29      0.29      0.29         7\n",
      "          30       0.40      0.50      0.44         4\n",
      "          31       0.62      0.54      0.58        46\n",
      "          32       0.35      0.23      0.27        31\n",
      "          33       0.31      0.21      0.25        19\n",
      "          34       0.33      0.33      0.33         3\n",
      "          35       0.20      0.38      0.26        32\n",
      "          36       0.33      0.25      0.29        16\n",
      "          37       0.50      0.29      0.36         7\n",
      "          38       0.24      0.24      0.24        67\n",
      "          39       0.36      0.22      0.28        36\n",
      "          40       0.55      0.53      0.54        32\n",
      "          41       0.90      0.56      0.69        16\n",
      "          42       0.59      0.70      0.64       210\n",
      "          43       0.59      0.49      0.54        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      0.33      0.40         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.57      0.48      0.52        25\n",
      "          49       0.59      0.52      0.55        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       1.00      0.40      0.57         5\n",
      "          52       0.68      0.59      0.63       181\n",
      "          53       0.44      0.44      0.44         9\n",
      "          54       0.53      0.38      0.44       159\n",
      "          55       0.46      0.55      0.50       536\n",
      "          56       0.45      0.32      0.37       202\n",
      "          57       0.52      0.62      0.56       829\n",
      "          58       0.41      0.35      0.38       471\n",
      "          59       0.60      0.27      0.37        66\n",
      "          60       0.22      0.08      0.12        24\n",
      "          61       0.67      0.22      0.33         9\n",
      "          62       0.27      0.08      0.12        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.50      0.40      0.44         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.50      0.69      0.58        13\n",
      "          67       0.80      0.80      0.80        15\n",
      "          68       0.55      0.38      0.44        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.86      0.63      0.73        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.53      0.34      0.41        68\n",
      "          73       0.50      0.33      0.40        18\n",
      "          74       0.33      0.11      0.16        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       1.00      0.40      0.57         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       1.00      0.58      0.74        12\n",
      "          82       1.00      0.50      0.67         2\n",
      "          83       0.42      0.62      0.50         8\n",
      "          84       0.50      0.33      0.40         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.85      0.85      0.85        13\n",
      "          87       0.50      0.17      0.25         6\n",
      "          88       1.00      0.83      0.91         6\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.00      0.00      0.00         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.75      0.50      0.60         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.60      0.60      0.60         5\n",
      "          98       0.00      0.00      0.00         4\n",
      "          99       1.00      0.25      0.40         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.67      0.33      0.44         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.59      0.62      0.60       102\n",
      "         104       0.59      0.46      0.52        41\n",
      "         105       0.54      0.65      0.59        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.40      0.25      0.31         8\n",
      "         108       0.50      0.33      0.40         3\n",
      "         109       0.71      0.62      0.67         8\n",
      "         110       1.00      0.11      0.20         9\n",
      "         111       0.67      0.36      0.47        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       0.67      0.40      0.50         5\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5588\n",
      "   macro avg       0.47      0.37      0.40      5588\n",
      "weighted avg       0.51      0.52      0.51      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Try the KNeighborsClassifier \n",
    "KN_clf = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [10],\n",
    "              'weights': ['distance']\n",
    "             }\n",
    "\n",
    "KN_CV = GridSearchCV(KN_clf, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "KN_CV.fit(X_train, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(KN_CV.best_score_)    \n",
    "print(KN_CV.best_params_) \n",
    "\n",
    "\n",
    "KN_y_pred = KN_CV.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(KN_y_pred, y_test))\n",
    "print(classification_report(y_test, KN_y_pred))\n",
    "rec_scores('KN', KN_y_pred)\n",
    "\n",
    "#Save model\n",
    "pickle.dump(KN_CV, open('models/KN_CV.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SMOTE oversampling to the training dataset to reduce bias introduced by the imbalanced dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train,y_train.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380995"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How big is the training set now?\n",
    "len(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4890837508947745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.96      0.96      0.96       112\n",
      "           2       0.75      0.75      0.75         8\n",
      "           3       0.91      0.72      0.81        29\n",
      "           4       0.94      0.84      0.89        19\n",
      "           5       0.67      0.80      0.73         5\n",
      "           6       0.32      0.39      0.35        23\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.54      0.48      0.51        46\n",
      "           9       0.75      0.73      0.74       156\n",
      "          10       0.41      0.55      0.47        29\n",
      "          11       0.50      0.50      0.50         2\n",
      "          12       0.43      0.50      0.46        12\n",
      "          13       0.26      0.35      0.30        51\n",
      "          14       0.77      0.85      0.81       215\n",
      "          15       0.61      0.40      0.48       110\n",
      "          16       0.94      1.00      0.97        16\n",
      "          17       0.19      0.20      0.19        15\n",
      "          18       1.00      0.71      0.83         7\n",
      "          19       0.62      0.59      0.61        61\n",
      "          20       0.58      0.40      0.47       534\n",
      "          21       0.07      0.14      0.09        14\n",
      "          22       0.44      0.41      0.43       210\n",
      "          23       0.81      0.89      0.85        19\n",
      "          24       0.35      0.40      0.37        45\n",
      "          25       0.36      0.36      0.36        11\n",
      "          26       0.27      0.50      0.35         8\n",
      "          27       0.20      0.20      0.20        10\n",
      "          28       0.36      0.48      0.41        25\n",
      "          29       0.44      0.57      0.50         7\n",
      "          30       0.04      0.50      0.07         4\n",
      "          31       0.57      0.61      0.59        46\n",
      "          32       0.40      0.39      0.39        31\n",
      "          33       0.11      0.47      0.18        19\n",
      "          34       0.08      0.33      0.12         3\n",
      "          35       0.37      0.44      0.40        32\n",
      "          36       0.20      0.25      0.22        16\n",
      "          37       0.44      0.57      0.50         7\n",
      "          38       0.27      0.21      0.24        67\n",
      "          39       0.19      0.17      0.18        36\n",
      "          40       0.86      0.75      0.80        32\n",
      "          41       0.80      0.75      0.77        16\n",
      "          42       0.71      0.59      0.65       210\n",
      "          43       0.44      0.58      0.50        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.17      0.33      0.22         6\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       0.33      0.50      0.40         2\n",
      "          48       0.52      0.64      0.57        25\n",
      "          49       0.52      0.60      0.56        91\n",
      "          50       0.33      0.50      0.40         2\n",
      "          51       0.50      0.40      0.44         5\n",
      "          52       0.68      0.55      0.61       181\n",
      "          53       0.21      0.44      0.29         9\n",
      "          54       0.42      0.43      0.43       159\n",
      "          55       0.51      0.49      0.50       536\n",
      "          56       0.36      0.46      0.40       202\n",
      "          57       0.58      0.36      0.44       829\n",
      "          58       0.40      0.45      0.43       471\n",
      "          59       0.19      0.50      0.28        66\n",
      "          60       0.10      0.25      0.15        24\n",
      "          61       0.50      0.33      0.40         9\n",
      "          62       0.14      0.34      0.19        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.33      0.80      0.47         5\n",
      "          65       0.29      1.00      0.44         2\n",
      "          66       0.52      0.92      0.67        13\n",
      "          67       0.88      0.93      0.90        15\n",
      "          68       0.38      0.69      0.49        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.45      0.68      0.54        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.46      0.25      0.32        68\n",
      "          73       0.39      0.39      0.39        18\n",
      "          74       0.07      0.11      0.08        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       1.00      0.20      0.33         5\n",
      "          77       0.20      0.40      0.27         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       1.00      1.00      1.00         3\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.73      0.67      0.70        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.42      0.62      0.50         8\n",
      "          84       0.33      0.33      0.33         3\n",
      "          85       0.50      0.20      0.29         5\n",
      "          86       1.00      1.00      1.00        13\n",
      "          87       0.25      0.17      0.20         6\n",
      "          88       1.00      0.83      0.91         6\n",
      "          89       1.00      1.00      1.00         4\n",
      "          90       1.00      0.60      0.75         5\n",
      "          91       0.29      0.40      0.33         5\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       0.71      0.83      0.77         6\n",
      "          94       0.20      0.50      0.29         2\n",
      "          95       0.67      1.00      0.80         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.56      1.00      0.71         5\n",
      "          98       0.00      0.00      0.00         4\n",
      "          99       1.00      1.00      1.00         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.17      0.17      0.17         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.60      0.54      0.57       102\n",
      "         104       0.57      0.59      0.58        41\n",
      "         105       0.48      0.61      0.54        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.75      0.75      0.75         8\n",
      "         108       1.00      1.00      1.00         3\n",
      "         109       0.75      0.75      0.75         8\n",
      "         110       0.33      0.44      0.38         9\n",
      "         111       0.38      0.41      0.39        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       0.80      0.80      0.80         5\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      5588\n",
      "   macro avg       0.48      0.51      0.47      5588\n",
      "weighted avg       0.53      0.49      0.50      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Use the same parameters as the previous RF model.\n",
    "RF_clf_res = RandomForestClassifier(random_state=42,\n",
    "                                max_depth = 100,\n",
    "                                min_samples_split = 2,\n",
    "                                min_samples_leaf = 2,\n",
    "                                n_estimators= 100,\n",
    "                                n_jobs = 4 \n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "RF_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "RF_y_pred_res = RF_clf_res.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(RF_y_pred_res, y_test))\n",
    "print(classification_report(y_test, RF_y_pred_res))\n",
    "rec_scores('RF_res', RF_y_pred_res)\n",
    "\n",
    "\n",
    "#Save model\n",
    "pickle.dump(RF_clf_res, open('models/RF_clf_res.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4858625626342162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.97      0.96      0.97       112\n",
      "           2       0.55      0.75      0.63         8\n",
      "           3       0.78      0.72      0.75        29\n",
      "           4       1.00      0.89      0.94        19\n",
      "           5       0.57      0.80      0.67         5\n",
      "           6       0.37      0.30      0.33        23\n",
      "           7       0.45      1.00      0.62         5\n",
      "           8       0.45      0.43      0.44        46\n",
      "           9       0.69      0.74      0.71       156\n",
      "          10       0.43      0.52      0.47        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.35      0.50      0.41        12\n",
      "          13       0.30      0.27      0.29        51\n",
      "          14       0.71      0.77      0.74       215\n",
      "          15       0.47      0.40      0.43       110\n",
      "          16       0.85      0.69      0.76        16\n",
      "          17       0.18      0.20      0.19        15\n",
      "          18       1.00      0.57      0.73         7\n",
      "          19       0.57      0.57      0.57        61\n",
      "          20       0.53      0.46      0.49       534\n",
      "          21       0.10      0.14      0.12        14\n",
      "          22       0.43      0.46      0.44       210\n",
      "          23       0.81      0.89      0.85        19\n",
      "          24       0.42      0.36      0.39        45\n",
      "          25       0.19      0.36      0.25        11\n",
      "          26       0.60      0.75      0.67         8\n",
      "          27       0.25      0.20      0.22        10\n",
      "          28       0.36      0.48      0.41        25\n",
      "          29       0.29      0.29      0.29         7\n",
      "          30       0.29      0.50      0.36         4\n",
      "          31       0.52      0.54      0.53        46\n",
      "          32       0.21      0.23      0.22        31\n",
      "          33       0.22      0.32      0.26        19\n",
      "          34       0.20      0.33      0.25         3\n",
      "          35       0.42      0.44      0.43        32\n",
      "          36       0.33      0.25      0.29        16\n",
      "          37       0.50      0.29      0.36         7\n",
      "          38       0.20      0.24      0.22        67\n",
      "          39       0.24      0.22      0.23        36\n",
      "          40       0.61      0.53      0.57        32\n",
      "          41       0.82      0.56      0.67        16\n",
      "          42       0.62      0.68      0.65       210\n",
      "          43       0.52      0.47      0.50        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      0.50      0.50         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.58      0.56      0.57        25\n",
      "          49       0.55      0.52      0.53        91\n",
      "          50       0.33      0.50      0.40         2\n",
      "          51       0.50      0.40      0.44         5\n",
      "          52       0.64      0.58      0.61       181\n",
      "          53       0.25      0.44      0.32         9\n",
      "          54       0.42      0.38      0.40       159\n",
      "          55       0.48      0.50      0.49       536\n",
      "          56       0.46      0.34      0.39       202\n",
      "          57       0.51      0.49      0.50       829\n",
      "          58       0.41      0.32      0.36       471\n",
      "          59       0.21      0.48      0.29        66\n",
      "          60       0.06      0.21      0.09        24\n",
      "          61       0.33      0.22      0.27         9\n",
      "          62       0.14      0.24      0.18        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.05      0.40      0.09         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.56      0.69      0.62        13\n",
      "          67       0.92      0.80      0.86        15\n",
      "          68       0.35      0.38      0.36        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.86      0.63      0.73        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.43      0.34      0.38        68\n",
      "          73       0.33      0.33      0.33        18\n",
      "          74       0.16      0.16      0.16        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.29      0.40      0.33         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.50      0.33      0.40         3\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.78      0.58      0.67        12\n",
      "          82       1.00      0.50      0.67         2\n",
      "          83       0.56      0.62      0.59         8\n",
      "          84       0.25      0.33      0.29         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.92      0.85      0.88        13\n",
      "          87       0.33      0.17      0.22         6\n",
      "          88       1.00      0.83      0.91         6\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       1.00      0.20      0.33         5\n",
      "          91       0.17      0.20      0.18         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.80      0.67      0.73         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.20      0.50      0.29         2\n",
      "          97       0.50      0.60      0.55         5\n",
      "          98       0.00      0.00      0.00         4\n",
      "          99       1.00      0.50      0.67         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.67      0.33      0.44         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.60      0.61      0.60       102\n",
      "         104       0.45      0.51      0.48        41\n",
      "         105       0.52      0.65      0.58        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.40      0.25      0.31         8\n",
      "         108       0.67      0.67      0.67         3\n",
      "         109       0.71      0.62      0.67         8\n",
      "         110       0.12      0.11      0.12         9\n",
      "         111       0.53      0.36      0.43        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       0.67      0.40      0.50         5\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      5588\n",
      "   macro avg       0.42      0.40      0.40      5588\n",
      "weighted avg       0.50      0.49      0.49      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Try the KNeighbors Classifier on the enhanced dataset\n",
    "\n",
    "KN_clf_res = KNeighborsClassifier(n_neighbors=10, weights = 'distance', n_jobs = 4)\n",
    "\n",
    "KN_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "KN_y_pred_res = KN_clf_res.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(KN_y_pred_res, y_test))\n",
    "print(classification_report(y_test, KN_y_pred_res))\n",
    "\n",
    "rec_scores('KN_res', KN_y_pred_res)\n",
    "\n",
    "pickle.dump(KN_clf_res, open('models/KN_CV_res.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How do all the classifiers compare:\n",
    "# RF - Random Forest\n",
    "# KN - Kneighbors\n",
    "# RF_res - Random Forest with SMOTE enhanced dataset\n",
    "# KN_Res - KNeighbors with SMOTE Enhanced Dataset\n",
    "\n",
    "pd.DataFrame(model_scores).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Classifier Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Random forest predictions, and reverse the label encoding on it and the actual cost code.\n",
    "df_output = pd.DataFrame({'Text':X_test_desc ,'Predicted Code':le.inverse_transform(RF_y_pred), 'Actual Code':le.inverse_transform(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00-10-17</td>\n",
       "      <td>geotechnical consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-61-13</td>\n",
       "      <td>subtrade bonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-30-12</td>\n",
       "      <td>project manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-30-14</td>\n",
       "      <td>project coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-30-23</td>\n",
       "      <td>finishing superintendent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cost Code               Description\n",
       "0  00-10-17   geotechnical consultant\n",
       "1  00-61-13            subtrade bonds\n",
       "2  01-30-12           project manager\n",
       "3  01-30-14       project coordinator\n",
       "4  01-30-23  finishing superintendent"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm the name_mapping loaded correctly\n",
    "name_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PST</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caulking firestop</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freight in</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PST</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PST</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Text Predicted Code Actual Code            Actual Code Desc.\n",
       "0                PST       07-84-10    07-84-10  firestopping trade contract\n",
       "1  caulking firestop       01-52-23    07-84-10  firestopping trade contract\n",
       "2        freight in        01-52-23    07-84-10  firestopping trade contract\n",
       "3                PST       07-84-10    07-84-10  firestopping trade contract\n",
       "4                PST       07-84-10    07-84-10  firestopping trade contract"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Map the actual cost code to its corresponding description\n",
    "out = df_output.merge(name_mapping, left_on='Actual Code',right_on='Cost Code')\n",
    "out.rename(index=str, columns={'Description':'Actual Code Desc.'}, inplace = True)\n",
    "out.drop(['Cost Code'], axis = 1, inplace = True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "      <th>Predicted Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PST</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PST</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PST</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firestopping pipes-INV#8770</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vestibules P4 P3 P2</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>07-84-10</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "      <td>firestopping trade contract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Text Predicted Code Actual Code  \\\n",
       "0                          PST       07-84-10    07-84-10   \n",
       "1                          PST       07-84-10    07-84-10   \n",
       "2                          PST       07-84-10    07-84-10   \n",
       "3  firestopping pipes-INV#8770       07-84-10    07-84-10   \n",
       "4          Vestibules P4 P3 P2       07-84-10    07-84-10   \n",
       "\n",
       "             Actual Code Desc.         Predicted Code Desc.  \n",
       "0  firestopping trade contract  firestopping trade contract  \n",
       "1  firestopping trade contract  firestopping trade contract  \n",
       "2  firestopping trade contract  firestopping trade contract  \n",
       "3  firestopping trade contract  firestopping trade contract  \n",
       "4  firestopping trade contract  firestopping trade contract  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Map the predicted cost code to its corresponding description\n",
    "out = out.merge(name_mapping, left_on='Predicted Code',right_on='Cost Code')\n",
    "out.drop(['Cost Code'], axis = 1, inplace=True)\n",
    "out.rename(index=str, columns={'Description':'Predicted Code Desc.'}, inplace=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-order columns for ease of reading\n",
    "cols = ['Text', 'Predicted Code','Predicted Code Desc.', 'Actual Code', 'Actual Code Desc.']\n",
    "out = out[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Predicted Code Desc.</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>Polarcon Accelerating - Bronze</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>Offix Marker whiteb. chi.ass.</td>\n",
       "      <td>01-52-22</td>\n",
       "      <td>field office supplies</td>\n",
       "      <td>01-52-22</td>\n",
       "      <td>field office supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>306860</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>field supplies</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>field supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>Fuel Surcharge-Per Load</td>\n",
       "      <td>03-31-42</td>\n",
       "      <td>concrete materials - below-grade horizontals</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>FREIGHT IN</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>field supplies</td>\n",
       "      <td>01-54-24</td>\n",
       "      <td>temporary stairway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Text Predicted Code  \\\n",
       "4427  Polarcon Accelerating - Bronze       03-31-41   \n",
       "5323   Offix Marker whiteb. chi.ass.       01-52-22   \n",
       "93                            306860       01-52-23   \n",
       "5179         Fuel Surcharge-Per Load       03-31-42   \n",
       "933                      FREIGHT IN        01-52-23   \n",
       "\n",
       "                              Predicted Code Desc. Actual Code  \\\n",
       "4427     concrete material - below-grade verticals    03-31-41   \n",
       "5323                         field office supplies    01-52-22   \n",
       "93                                  field supplies    01-52-23   \n",
       "5179  concrete materials - below-grade horizontals    03-31-40   \n",
       "933                                 field supplies    01-54-24   \n",
       "\n",
       "                              Actual Code Desc.  \n",
       "4427  concrete material - below-grade verticals  \n",
       "5323                      field office supplies  \n",
       "93                               field supplies  \n",
       "5179               concrete material - footings  \n",
       "933                          temporary stairway  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check a random sample of codes.\n",
    "out.sample(n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
