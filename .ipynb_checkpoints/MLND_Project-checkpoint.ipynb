{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company #</th>\n",
       "      <th>Purchase Order</th>\n",
       "      <th>Item</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unit of Measure</th>\n",
       "      <th>Units</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Cost Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-001</td>\n",
       "      <td>1</td>\n",
       "      <td>Paragon Electrical Installations Ltd.</td>\n",
       "      <td>Additional smoke detector/re-verification</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>26-20-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-002</td>\n",
       "      <td>1</td>\n",
       "      <td>Accurate Aluminum Ltd</td>\n",
       "      <td>S&amp;I railing as per quote Aug. 13  2015</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>05-52-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-003</td>\n",
       "      <td>1</td>\n",
       "      <td>Dura Productions</td>\n",
       "      <td>S&amp;I metal ramp</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>05-52-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-004</td>\n",
       "      <td>1</td>\n",
       "      <td>Friesen Floors &amp; Window Fashions Ltd</td>\n",
       "      <td>S&amp;I hardwood flooring for enclosed balcony area</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>09-64-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1209-1-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Alba Painting Ltd.</td>\n",
       "      <td>Painting of two offices</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>09-91-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company # Purchase Order  Item                                 Vendor  \\\n",
       "0          8       1200-001     1  Paragon Electrical Installations Ltd.   \n",
       "1          8       1200-002     1                  Accurate Aluminum Ltd   \n",
       "2          8       1200-003     1                       Dura Productions   \n",
       "3          8       1200-004     1   Friesen Floors & Window Fashions Ltd   \n",
       "4          8      1209-1-01     1                     Alba Painting Ltd.   \n",
       "\n",
       "                                       Description Unit of Measure Units  \\\n",
       "0        Additional smoke detector/re-verification              LS     0   \n",
       "1           S&I railing as per quote Aug. 13  2015              LS     0   \n",
       "2                                   S&I metal ramp              LS     0   \n",
       "3  S&I hardwood flooring for enclosed balcony area              LS     0   \n",
       "4                          Painting of two offices              LS     0   \n",
       "\n",
       "   Unit Cost    Cost Cost Code  \n",
       "0        0.0  1444.0  26-20-20  \n",
       "1        0.0   500.0  05-52-20  \n",
       "2        0.0   795.0  05-52-20  \n",
       "3        0.0  2314.0  09-64-33  \n",
       "4        0.0   900.0  09-91-40  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data from CSV files.\n",
    "df = pd.read_csv('raw_data/PO_Dataset.csv')\n",
    "name_mapping = pd.read_csv('clean_data/Clean_Code_Master_list.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Convert the Units column to float\n",
    "df['Units'] = pd.to_numeric(df['Units'], errors='coerce').fillna(0)\n",
    "df['Units'] = df['Units'].astype('float64')\n",
    "\n",
    "#Drop lines with null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Read in Master list of valid cost codes\n",
    "df_ml = pd.read_csv('raw_data/Code_Master_list.csv')\n",
    "\n",
    "#Drop rows where the cost code is not in the master list\n",
    "df = df[df['Cost Code'].isin(df_ml['Cost Code'])].dropna()\n",
    "\n",
    "#Create a new dataframe that takes only the 90th quartile of data from the 3 numerical columns.\n",
    "df_90 = df[df['Cost'] < df['Cost'].quantile(.90)]\n",
    "df_90 = df_90[df_90['Units'] < df_90['Units'].quantile(.90)]\n",
    "df_90 = df_90[df_90['Unit Cost'] < df_90['Unit Cost'].quantile(.90)]\n",
    "\n",
    "# It's a good practice to scale numerical data\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() \n",
    "numerical = ['Units','Unit Cost','Cost']\n",
    "\n",
    "df_90[numerical] = scaler.fit_transform(df_90[numerical])\n",
    "\n",
    "# When splitting for training and testing later, we'll need a minimum of 2 examples of each cost code.\n",
    "# Assign cost code to a variable\n",
    "df_count = df_90['Cost Code'].value_counts()\n",
    "\n",
    "#New dataframe only includes lines with cost codes with a count of 10 or greater\n",
    "df_90 = df_90[~df_90['Cost Code'].isin(df_count[df_count < 10].index)]\n",
    "\n",
    "\n",
    "#One Hot Encode categorical features\n",
    "categorical = ['Vendor', 'Unit of Measure']\n",
    "df_90 = pd.get_dummies(df_90, columns = categorical )\n",
    "\n",
    "#Numerically encode cost codes.\n",
    "le = LabelEncoder()\n",
    "cost_code = df_90['Cost Code']\n",
    "df_90['Cost Code Encoded'] = le.fit_transform(cost_code)\n",
    "\n",
    "#drop features I won't be using\n",
    "df_90 = df_90.drop(['Company #','Purchase Order', 'Item'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "df = df_90\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Separate the target variable from the features\n",
    "cost_codes = df['Cost Code Encoded']\n",
    "features = df.drop(['Cost Code','Cost Code Encoded'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn train test split to split the data into training and testing sets. \n",
    "#Testing set is 20% of total dataset size.\n",
    "#Stratify the data so we don't introduce bias in the sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    cost_codes,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = cost_codes\n",
    "                                                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22349, 418)\n",
      "(22349,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Units</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Vendor_1110438 B.C. Ltd</th>\n",
       "      <th>Vendor_4s Scaffolding</th>\n",
       "      <th>Vendor_596143 BC LTD DBA AVANTE 2000</th>\n",
       "      <th>Vendor_7 Star Security Services Inc</th>\n",
       "      <th>Vendor_A &amp; A Testing Ltd.</th>\n",
       "      <th>Vendor_A Plus Cleaning and Janitorial Ltd.</th>\n",
       "      <th>...</th>\n",
       "      <th>Unit of Measure_WKS</th>\n",
       "      <th>Unit of Measure_kg</th>\n",
       "      <th>Unit of Measure_km</th>\n",
       "      <th>Unit of Measure_kw</th>\n",
       "      <th>Unit of Measure_l</th>\n",
       "      <th>Unit of Measure_m</th>\n",
       "      <th>Unit of Measure_m3</th>\n",
       "      <th>Unit of Measure_m3</th>\n",
       "      <th>Unit of Measure_mL</th>\n",
       "      <th>Unit of Measure_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>construction heater inv 216617G-1 May 2018</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.979224</td>\n",
       "      <td>0.918374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14527</th>\n",
       "      <td>Environmental charge - Applies per m3 to all c...</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.979916</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27165</th>\n",
       "      <td>2\" nails</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.979543</td>\n",
       "      <td>0.908641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>Fuel Surcharge  $1.00/L to $1.20/L</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.979801</td>\n",
       "      <td>0.908284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26991</th>\n",
       "      <td>pst</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.979224</td>\n",
       "      <td>0.908724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description     Units  Unit Cost  \\\n",
       "3857          construction heater inv 216617G-1 May 2018  0.998941   0.979224   \n",
       "14527  Environmental charge - Applies per m3 to all c...  0.999327   0.979916   \n",
       "27165                                           2\" nails  0.999108   0.979543   \n",
       "6676                  Fuel Surcharge  $1.00/L to $1.20/L  0.998974   0.979801   \n",
       "26991                                                pst  0.998941   0.979224   \n",
       "\n",
       "           Cost  Vendor_1110438 B.C. Ltd  Vendor_4s Scaffolding  \\\n",
       "3857   0.918374                        0                      0   \n",
       "14527  0.910891                        0                      0   \n",
       "27165  0.908641                        0                      0   \n",
       "6676   0.908284                        0                      0   \n",
       "26991  0.908724                        0                      0   \n",
       "\n",
       "       Vendor_596143 BC LTD DBA AVANTE 2000  \\\n",
       "3857                                      0   \n",
       "14527                                     0   \n",
       "27165                                     0   \n",
       "6676                                      0   \n",
       "26991                                     0   \n",
       "\n",
       "       Vendor_7 Star Security Services Inc  Vendor_A & A Testing Ltd.  \\\n",
       "3857                                     0                          0   \n",
       "14527                                    0                          0   \n",
       "27165                                    0                          0   \n",
       "6676                                     0                          0   \n",
       "26991                                    0                          0   \n",
       "\n",
       "       Vendor_A Plus Cleaning and Janitorial Ltd.        ...          \\\n",
       "3857                                            0        ...           \n",
       "14527                                           0        ...           \n",
       "27165                                           0        ...           \n",
       "6676                                            0        ...           \n",
       "26991                                           0        ...           \n",
       "\n",
       "       Unit of Measure_WKS  Unit of Measure_kg  Unit of Measure_km  \\\n",
       "3857                     0                   0                   0   \n",
       "14527                    0                   0                   0   \n",
       "27165                    0                   0                   0   \n",
       "6676                     0                   0                   0   \n",
       "26991                    0                   0                   0   \n",
       "\n",
       "       Unit of Measure_kw  Unit of Measure_l  Unit of Measure_m  \\\n",
       "3857                    0                  0                  0   \n",
       "14527                   0                  0                  0   \n",
       "27165                   0                  0                  0   \n",
       "6676                    0                  0                  0   \n",
       "26991                   0                  0                  0   \n",
       "\n",
       "       Unit of Measure_m3  Unit of Measure_m3   Unit of Measure_mL  \\\n",
       "3857                    0                    0                   0   \n",
       "14527                   1                    0                   0   \n",
       "27165                   0                    0                   0   \n",
       "6676                    0                    0                   0   \n",
       "26991                   0                    0                   0   \n",
       "\n",
       "       Unit of Measure_t  \n",
       "3857                   0  \n",
       "14527                  0  \n",
       "27165                  0  \n",
       "6676                   0  \n",
       "26991                  0  \n",
       "\n",
       "[5 rows x 418 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm the number of samples in X and y training data are the same\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split out X_train and X_test Descriptions for use in sepearate model.\n",
    "X_train_desc = X_train['Description'].copy()\n",
    "X_train = X_train.drop('Description', axis=1)\n",
    "\n",
    "X_test_desc = X_test['Description'].copy()\n",
    "X_test = X_test.drop('Description', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.4164806783687687\n",
      "{'clf__alpha': 0.0001, 'clf__max_iter': 20, 'clf__penalty': 'l2'}\n",
      "\n",
      " Test output\n",
      "accuracy 43.6292%\n",
      "f1_score 0.4458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.92      0.96      0.94       112\n",
      "           2       0.32      0.75      0.44         8\n",
      "           3       0.88      0.72      0.79        29\n",
      "           4       0.76      0.68      0.72        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.58      0.48      0.52        23\n",
      "           7       1.00      0.60      0.75         5\n",
      "           8       0.49      0.39      0.43        46\n",
      "           9       0.56      0.85      0.68       156\n",
      "          10       0.48      0.34      0.40        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.62      0.42      0.50        12\n",
      "          13       0.16      0.18      0.17        51\n",
      "          14       0.60      0.73      0.66       215\n",
      "          15       0.36      0.18      0.24       110\n",
      "          16       0.17      0.44      0.25        16\n",
      "          17       0.18      0.13      0.15        15\n",
      "          18       0.75      0.86      0.80         7\n",
      "          19       0.62      0.54      0.58        61\n",
      "          20       0.40      0.48      0.43       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.36      0.36      0.36       210\n",
      "          23       0.78      0.95      0.86        19\n",
      "          24       0.58      0.33      0.42        45\n",
      "          25       0.29      0.18      0.22        11\n",
      "          26       0.20      0.12      0.15         8\n",
      "          27       0.33      0.10      0.15        10\n",
      "          28       0.48      0.44      0.46        25\n",
      "          29       0.50      0.29      0.36         7\n",
      "          30       0.33      0.75      0.46         4\n",
      "          31       0.49      0.37      0.42        46\n",
      "          32       0.50      0.42      0.46        31\n",
      "          33       0.25      0.05      0.09        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.24      0.25      0.24        32\n",
      "          36       0.50      0.06      0.11        16\n",
      "          37       0.56      0.71      0.63         7\n",
      "          38       0.33      0.22      0.27        67\n",
      "          39       0.28      0.19      0.23        36\n",
      "          40       0.56      0.59      0.58        32\n",
      "          41       0.57      0.25      0.35        16\n",
      "          42       0.60      0.71      0.65       210\n",
      "          43       0.50      0.34      0.40        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      0.17      0.25         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.61      0.44      0.51        25\n",
      "          49       0.55      0.34      0.42        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.43      0.56      0.48       181\n",
      "          53       0.71      0.56      0.63         9\n",
      "          54       0.21      0.25      0.23       159\n",
      "          55       0.46      0.40      0.43       536\n",
      "          56       0.44      0.18      0.26       202\n",
      "          57       0.49      0.43      0.45       829\n",
      "          58       0.28      0.45      0.34       471\n",
      "          59       0.19      0.17      0.18        66\n",
      "          60       0.00      0.00      0.00        24\n",
      "          61       0.50      0.11      0.18         9\n",
      "          62       0.29      0.05      0.09        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.60      0.92      0.73        13\n",
      "          67       0.73      0.73      0.73        15\n",
      "          68       0.38      0.31      0.34        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.57      0.84      0.68        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.34      0.28      0.31        68\n",
      "          73       0.64      0.39      0.48        18\n",
      "          74       0.20      0.05      0.08        19\n",
      "          75       0.50      0.14      0.22         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       1.00      0.60      0.75         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       0.57      0.33      0.42        12\n",
      "          82       0.33      0.50      0.40         2\n",
      "          83       0.25      0.50      0.33         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.57      0.62      0.59        13\n",
      "          87       0.05      0.33      0.09         6\n",
      "          88       0.75      0.50      0.60         6\n",
      "          89       0.50      0.50      0.50         4\n",
      "          90       1.00      0.20      0.33         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.17      0.17      0.17         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       0.25      0.25      0.25         4\n",
      "          99       0.00      0.00      0.00         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.67      0.33      0.44         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.55      0.53      0.54       102\n",
      "         104       0.58      0.51      0.55        41\n",
      "         105       0.45      0.22      0.29        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.12      0.12      0.12         8\n",
      "         108       0.00      0.00      0.00         3\n",
      "         109       0.50      0.62      0.56         8\n",
      "         110       0.20      0.11      0.14         9\n",
      "         111       0.26      0.45      0.33        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.20      0.33         5\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      5588\n",
      "   macro avg       0.37      0.31      0.32      5588\n",
      "weighted avg       0.44      0.44      0.43      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Create a pipeline for vectorizing the description text and calculating the tfidf value, then traom the SGDClassifier\n",
    "\n",
    "SGDC_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(random_state=42, tol = 1e-3)),\n",
    "               ])\n",
    "\n",
    "#Configure the parameters to iterate through\n",
    "parameters = {\n",
    "    #'clf__loss':['hinge','log'],\n",
    "    #'clf__penalty':['l1','l2'],\n",
    "    #'clf__alpha':[1e-3,1e-4],\n",
    "    #'clf__max_iter':[15,20,25]\n",
    "    'clf__penalty':['l2'],\n",
    "    'clf__alpha':[1e-4],\n",
    "    'clf__max_iter':[20]\n",
    "}\n",
    "\n",
    "\n",
    "#Configure Gridsearch cross validation\n",
    "SGDC_CV = GridSearchCV(SGDC_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "#Fit the model and execute the gridsearch\n",
    "SGDC_CV.fit(X_train_desc, y_train)\n",
    "\n",
    "#Print the \n",
    "print('Best score and parameter combination = ')\n",
    "print(SGDC_CV.best_score_)    \n",
    "print(SGDC_CV.best_params_) \n",
    "\n",
    "\n",
    "SGDC_y_pred = SGDC_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(SGDC_y_pred, y_test)))\n",
    "print(classification_report(y_test, SGDC_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(SGDC_CV, open('models/SGDC_CV.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.43893891024433335\n",
      "{'clf__C': 10, 'clf__max_iter': 100, 'clf__solver': 'saga', 'clf__tol': 0.01}\n",
      "accuracy 0.49534717251252686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.95      0.95      0.95       112\n",
      "           2       0.54      0.88      0.67         8\n",
      "           3       0.83      0.66      0.73        29\n",
      "           4       0.88      0.74      0.80        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.50      0.52      0.51        23\n",
      "           7       1.00      0.60      0.75         5\n",
      "           8       0.53      0.39      0.45        46\n",
      "           9       0.66      0.83      0.73       156\n",
      "          10       0.69      0.31      0.43        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.56      0.42      0.48        12\n",
      "          13       0.34      0.20      0.25        51\n",
      "          14       0.65      0.68      0.67       215\n",
      "          15       0.36      0.29      0.32       110\n",
      "          16       0.83      0.62      0.71        16\n",
      "          17       0.50      0.07      0.12        15\n",
      "          18       1.00      0.86      0.92         7\n",
      "          19       0.70      0.54      0.61        61\n",
      "          20       0.39      0.68      0.49       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.40      0.38      0.39       210\n",
      "          23       0.90      0.95      0.92        19\n",
      "          24       0.57      0.38      0.45        45\n",
      "          25       0.67      0.18      0.29        11\n",
      "          26       1.00      0.38      0.55         8\n",
      "          27       0.33      0.10      0.15        10\n",
      "          28       0.43      0.52      0.47        25\n",
      "          29       0.40      0.29      0.33         7\n",
      "          30       0.33      0.25      0.29         4\n",
      "          31       0.45      0.33      0.38        46\n",
      "          32       0.41      0.39      0.40        31\n",
      "          33       0.33      0.05      0.09        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.39      0.22      0.28        32\n",
      "          36       0.50      0.19      0.27        16\n",
      "          37       0.75      0.86      0.80         7\n",
      "          38       0.49      0.28      0.36        67\n",
      "          39       0.56      0.25      0.35        36\n",
      "          40       0.79      0.59      0.68        32\n",
      "          41       0.43      0.19      0.26        16\n",
      "          42       0.64      0.72      0.68       210\n",
      "          43       0.52      0.32      0.40        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      0.17      0.25         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.79      0.44      0.56        25\n",
      "          49       0.42      0.40      0.41        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.69      0.59      0.63       181\n",
      "          53       0.71      0.56      0.63         9\n",
      "          54       0.55      0.14      0.22       159\n",
      "          55       0.42      0.50      0.46       536\n",
      "          56       0.76      0.18      0.29       202\n",
      "          57       0.44      0.79      0.57       829\n",
      "          58       0.42      0.13      0.20       471\n",
      "          59       0.50      0.21      0.30        66\n",
      "          60       0.00      0.00      0.00        24\n",
      "          61       0.33      0.33      0.33         9\n",
      "          62       0.25      0.05      0.09        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.85      0.85      0.85        13\n",
      "          67       0.77      0.67      0.71        15\n",
      "          68       0.60      0.38      0.46        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.76      0.84      0.80        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.43      0.38      0.41        68\n",
      "          73       0.67      0.33      0.44        18\n",
      "          74       0.40      0.11      0.17        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       1.00      0.60      0.75         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       1.00      0.25      0.40         4\n",
      "          81       0.75      0.25      0.38        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.36      0.50      0.42         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.73      0.62      0.67        13\n",
      "          87       0.67      0.33      0.44         6\n",
      "          88       0.75      0.50      0.60         6\n",
      "          89       0.75      0.75      0.75         4\n",
      "          90       0.67      0.40      0.50         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.17      0.29         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       1.00      0.25      0.40         4\n",
      "          99       0.00      0.00      0.00         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.50      0.33      0.40         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.51      0.57      0.54       102\n",
      "         104       0.66      0.51      0.58        41\n",
      "         105       0.50      0.35      0.41        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.14      0.12      0.13         8\n",
      "         108       1.00      0.33      0.50         3\n",
      "         109       0.75      0.75      0.75         8\n",
      "         110       0.14      0.11      0.12         9\n",
      "         111       0.90      0.41      0.56        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.20      0.33         5\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      5588\n",
      "   macro avg       0.46      0.33      0.36      5588\n",
      "weighted avg       0.51      0.50      0.46      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(random_state=42,multi_class='multinomial')),\n",
    "               ])\n",
    "parameters = {\n",
    "    'clf__C':[10],\n",
    "    'clf__solver':['saga'],\n",
    "    'clf__max_iter':[100],\n",
    "    'clf__tol': [0.01]\n",
    "}\n",
    "\n",
    "#Weighted F1 score takes into account the imbalance of the classes\n",
    "LR_CV = GridSearchCV(LR_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose=5)\n",
    "\n",
    "LR_CV.fit(X_train_desc, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(LR_CV.best_score_)    \n",
    "print(LR_CV.best_params_) \n",
    "\n",
    "\n",
    "LR_y_pred = LR_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(LR_y_pred, y_test)))\n",
    "print(classification_report(y_test, LR_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(LR_CV, open('models/LR_CV.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Logistic Regression model had the best accuracy, load the model saved to file\n",
    "LR_CV = pickle.load(open('models/LR_CV.sav', 'rb'))\n",
    "\n",
    "\n",
    "# Append its prediction to the training and testing datasets to create a new feature\n",
    "X_train['Desc Pred'] = LR_CV.predict(X_train_desc)\n",
    "X_test['Desc Pred'] = LR_CV.predict(X_test_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  1.3min remaining:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.5475903445765329\n",
      "{'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 700}\n",
      "\n",
      " Test output\n",
      "accuracy 53.6686%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.92      0.95      0.93       112\n",
      "           2       0.86      0.75      0.80         8\n",
      "           3       0.75      0.62      0.68        29\n",
      "           4       0.91      0.53      0.67        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       1.00      0.26      0.41        23\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.65      0.28      0.39        46\n",
      "           9       0.73      0.78      0.75       156\n",
      "          10       0.75      0.21      0.32        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       1.00      0.58      0.74        12\n",
      "          13       0.75      0.18      0.29        51\n",
      "          14       0.73      0.74      0.73       215\n",
      "          15       0.51      0.39      0.44       110\n",
      "          16       1.00      0.94      0.97        16\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.86      0.86      0.86         7\n",
      "          19       0.95      0.57      0.71        61\n",
      "          20       0.38      0.81      0.52       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.43      0.43      0.43       210\n",
      "          23       0.86      0.95      0.90        19\n",
      "          24       0.59      0.22      0.32        45\n",
      "          25       0.50      0.09      0.15        11\n",
      "          26       1.00      0.25      0.40         8\n",
      "          27       1.00      0.30      0.46        10\n",
      "          28       0.42      0.44      0.43        25\n",
      "          29       0.75      0.43      0.55         7\n",
      "          30       0.50      0.25      0.33         4\n",
      "          31       0.88      0.46      0.60        46\n",
      "          32       0.50      0.32      0.39        31\n",
      "          33       0.00      0.00      0.00        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.60      0.19      0.29        32\n",
      "          36       0.33      0.19      0.24        16\n",
      "          37       1.00      0.43      0.60         7\n",
      "          38       0.52      0.21      0.30        67\n",
      "          39       0.77      0.28      0.41        36\n",
      "          40       0.96      0.81      0.88        32\n",
      "          41       1.00      0.25      0.40        16\n",
      "          42       0.57      0.76      0.65       210\n",
      "          43       0.59      0.25      0.35        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.80      0.48      0.60        25\n",
      "          49       0.70      0.51      0.59        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.87      0.64      0.73       181\n",
      "          53       0.75      0.33      0.46         9\n",
      "          54       0.71      0.28      0.40       159\n",
      "          55       0.50      0.52      0.51       536\n",
      "          56       0.71      0.27      0.39       202\n",
      "          57       0.46      0.81      0.59       829\n",
      "          58       0.52      0.24      0.32       471\n",
      "          59       0.67      0.21      0.32        66\n",
      "          60       0.00      0.00      0.00        24\n",
      "          61       0.33      0.11      0.17         9\n",
      "          62       0.00      0.00      0.00        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.91      0.77      0.83        13\n",
      "          67       0.92      0.80      0.86        15\n",
      "          68       0.27      0.19      0.22        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.73      0.84      0.78        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.42      0.40      0.41        68\n",
      "          73       1.00      0.11      0.20        18\n",
      "          74       0.33      0.11      0.16        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       1.00      0.20      0.33         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.50      0.50      0.50         4\n",
      "          81       0.78      0.58      0.67        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.80      0.50      0.62         8\n",
      "          84       0.40      0.67      0.50         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       1.00      0.62      0.76        13\n",
      "          87       1.00      0.17      0.29         6\n",
      "          88       0.83      0.83      0.83         6\n",
      "          89       1.00      0.50      0.67         4\n",
      "          90       1.00      0.60      0.75         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.17      0.29         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       1.00      0.50      0.67         4\n",
      "          99       1.00      1.00      1.00         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.50      0.17      0.25         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.56      0.57      0.57       102\n",
      "         104       0.81      0.51      0.63        41\n",
      "         105       0.75      0.52      0.62        23\n",
      "         106       1.00      0.33      0.50         3\n",
      "         107       0.75      0.38      0.50         8\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       1.00      0.75      0.86         8\n",
      "         110       0.33      0.22      0.27         9\n",
      "         111       0.53      0.41      0.46        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      5588\n",
      "   macro avg       0.53      0.34      0.39      5588\n",
      "weighted avg       0.57      0.54      0.51      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Try a random forest ensemble classifier to evaluate the numeric features plus the predicted feature\n",
    "RF_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "parameters = {'max_depth': [100],\n",
    "              'min_samples_split': [2],\n",
    "              'min_samples_leaf': [2],\n",
    "              'n_estimators': [700]\n",
    "             }\n",
    "\n",
    "RF_CV = GridSearchCV(RF_clf, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "RF_CV.fit(X_train, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(RF_CV.best_score_)    \n",
    "print(RF_CV.best_params_) \n",
    "\n",
    "\n",
    "RF_y_pred = RF_CV.predict(X_test)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(RF_y_pred, y_test)))\n",
    "print(classification_report(y_test, RF_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(RF_CV, open('models/RF_CV.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_scores(name, y_pred):\n",
    "\n",
    "    model_scores[name] = classification_report(y_test, y_pred, output_dict=True)['weighted avg']\n",
    "    model_scores[name]['accuracy'] = accuracy_score(y_pred, y_test)\n",
    "    model_scores[name].pop('support',None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rec_scores('RF', RF_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a797e74e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What do the feature importances look like?\n",
    "(pd.Series(RF_CV.best_estimator_.feature_importances_, index=X_train.columns).nlargest(4).plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:  2.2min remaining:   32.7s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.6238744217355217\n",
      "{'n_neighbors': 10, 'weights': 'distance'}\n",
      "accuracy 0.5236220472440944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.95      0.96      0.95       112\n",
      "           2       0.70      0.88      0.78         8\n",
      "           3       0.77      0.69      0.73        29\n",
      "           4       0.87      0.68      0.76        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.57      0.57      0.57        23\n",
      "           7       1.00      0.60      0.75         5\n",
      "           8       0.57      0.43      0.49        46\n",
      "           9       0.76      0.78      0.77       156\n",
      "          10       0.48      0.38      0.42        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.69      0.75      0.72        12\n",
      "          13       0.33      0.29      0.31        51\n",
      "          14       0.70      0.70      0.70       215\n",
      "          15       0.41      0.42      0.41       110\n",
      "          16       0.87      0.81      0.84        16\n",
      "          17       0.60      0.20      0.30        15\n",
      "          18       1.00      0.86      0.92         7\n",
      "          19       0.66      0.62      0.64        61\n",
      "          20       0.46      0.61      0.52       534\n",
      "          21       0.17      0.07      0.10        14\n",
      "          22       0.41      0.44      0.42       210\n",
      "          23       0.86      0.95      0.90        19\n",
      "          24       0.60      0.47      0.52        45\n",
      "          25       0.29      0.18      0.22        11\n",
      "          26       0.80      0.50      0.62         8\n",
      "          27       0.50      0.30      0.37        10\n",
      "          28       0.35      0.44      0.39        25\n",
      "          29       0.57      0.57      0.57         7\n",
      "          30       0.40      0.50      0.44         4\n",
      "          31       0.62      0.50      0.55        46\n",
      "          32       0.44      0.39      0.41        31\n",
      "          33       0.25      0.11      0.15        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.33      0.22      0.26        32\n",
      "          36       0.27      0.19      0.22        16\n",
      "          37       0.67      0.86      0.75         7\n",
      "          38       0.33      0.28      0.31        67\n",
      "          39       0.54      0.42      0.47        36\n",
      "          40       0.85      0.69      0.76        32\n",
      "          41       0.56      0.31      0.40        16\n",
      "          42       0.56      0.77      0.64       210\n",
      "          43       0.52      0.42      0.46        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.33      0.17      0.22         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.60      0.48      0.53        25\n",
      "          49       0.61      0.51      0.55        91\n",
      "          50       1.00      0.50      0.67         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.64      0.64      0.64       181\n",
      "          53       0.42      0.56      0.48         9\n",
      "          54       0.49      0.36      0.41       159\n",
      "          55       0.46      0.52      0.48       536\n",
      "          56       0.43      0.37      0.40       202\n",
      "          57       0.50      0.65      0.57       829\n",
      "          58       0.45      0.29      0.36       471\n",
      "          59       0.49      0.29      0.36        66\n",
      "          60       0.00      0.00      0.00        24\n",
      "          61       0.43      0.33      0.38         9\n",
      "          62       0.38      0.21      0.27        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.92      0.85      0.88        13\n",
      "          67       0.83      0.67      0.74        15\n",
      "          68       0.56      0.31      0.40        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.83      0.79      0.81        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.44      0.37      0.40        68\n",
      "          73       0.45      0.28      0.34        18\n",
      "          74       0.25      0.11      0.15        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.75      0.60      0.67         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       1.00      0.33      0.50         3\n",
      "          80       1.00      0.25      0.40         4\n",
      "          81       0.70      0.58      0.64        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.36      0.50      0.42         8\n",
      "          84       0.20      0.33      0.25         3\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.75      0.69      0.72        13\n",
      "          87       1.00      0.67      0.80         6\n",
      "          88       0.75      0.50      0.60         6\n",
      "          89       0.75      0.75      0.75         4\n",
      "          90       0.67      0.40      0.50         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.17      0.29         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.67      0.40      0.50         5\n",
      "          98       0.50      0.25      0.33         4\n",
      "          99       0.00      0.00      0.00         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.50      0.33      0.40         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.53      0.63      0.57       102\n",
      "         104       0.50      0.59      0.54        41\n",
      "         105       0.69      0.48      0.56        23\n",
      "         106       0.75      1.00      0.86         3\n",
      "         107       0.33      0.25      0.29         8\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       0.75      0.75      0.75         8\n",
      "         110       0.25      0.22      0.24         9\n",
      "         111       0.64      0.41      0.50        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5588\n",
      "   macro avg       0.49      0.39      0.42      5588\n",
      "weighted avg       0.52      0.52      0.51      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Try the KNeighborsClassifier \n",
    "KN_clf = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [10],\n",
    "              'weights': ['distance']\n",
    "             }\n",
    "\n",
    "KN_CV = GridSearchCV(KN_clf, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "KN_CV.fit(X_train, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(KN_CV.best_score_)    \n",
    "print(KN_CV.best_params_) \n",
    "\n",
    "\n",
    "KN_y_pred = KN_CV.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(KN_y_pred, y_test))\n",
    "print(classification_report(y_test, KN_y_pred))\n",
    "rec_scores('KN', KN_y_pred)\n",
    "\n",
    "#Save model\n",
    "pickle.dump(KN_CV, open('models/KN_CV.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SMOTE oversampling to the training dataset to to reduce bias introduced by the imbalanced dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train,y_train.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380995"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How big is the training set now?\n",
    "len(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.48067287043664997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.97      0.95      0.96       112\n",
      "           2       0.50      1.00      0.67         8\n",
      "           3       0.63      0.66      0.64        29\n",
      "           4       0.79      0.58      0.67        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.59      0.57      0.58        23\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.65      0.43      0.52        46\n",
      "           9       0.78      0.70      0.74       156\n",
      "          10       0.26      0.41      0.32        29\n",
      "          11       0.33      1.00      0.50         2\n",
      "          12       0.69      0.75      0.72        12\n",
      "          13       0.28      0.41      0.33        51\n",
      "          14       0.75      0.72      0.74       215\n",
      "          15       0.49      0.45      0.47       110\n",
      "          16       0.88      0.94      0.91        16\n",
      "          17       0.15      0.27      0.20        15\n",
      "          18       0.60      0.86      0.71         7\n",
      "          19       0.73      0.66      0.69        61\n",
      "          20       0.62      0.39      0.48       534\n",
      "          21       0.08      0.14      0.10        14\n",
      "          22       0.47      0.38      0.42       210\n",
      "          23       0.82      0.95      0.88        19\n",
      "          24       0.47      0.44      0.45        45\n",
      "          25       0.20      0.18      0.19        11\n",
      "          26       0.13      0.50      0.21         8\n",
      "          27       0.50      0.30      0.37        10\n",
      "          28       0.25      0.52      0.34        25\n",
      "          29       0.45      0.71      0.56         7\n",
      "          30       0.06      0.75      0.11         4\n",
      "          31       0.60      0.52      0.56        46\n",
      "          32       0.41      0.42      0.41        31\n",
      "          33       0.14      0.21      0.17        19\n",
      "          34       0.01      0.33      0.02         3\n",
      "          35       0.28      0.34      0.31        32\n",
      "          36       0.24      0.38      0.29        16\n",
      "          37       0.43      0.86      0.57         7\n",
      "          38       0.30      0.27      0.28        67\n",
      "          39       0.39      0.39      0.39        36\n",
      "          40       0.97      0.88      0.92        32\n",
      "          41       0.88      0.44      0.58        16\n",
      "          42       0.79      0.64      0.71       210\n",
      "          43       0.45      0.47      0.46        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.29      0.33      0.31         6\n",
      "          46       0.67      1.00      0.80         2\n",
      "          47       0.33      0.50      0.40         2\n",
      "          48       0.50      0.48      0.49        25\n",
      "          49       0.55      0.58      0.57        91\n",
      "          50       0.50      1.00      0.67         2\n",
      "          51       0.30      0.60      0.40         5\n",
      "          52       0.67      0.64      0.66       181\n",
      "          53       0.50      0.56      0.53         9\n",
      "          54       0.31      0.36      0.33       159\n",
      "          55       0.53      0.47      0.50       536\n",
      "          56       0.39      0.49      0.43       202\n",
      "          57       0.58      0.38      0.46       829\n",
      "          58       0.45      0.37      0.40       471\n",
      "          59       0.19      0.61      0.29        66\n",
      "          60       0.02      0.04      0.03        24\n",
      "          61       0.33      0.33      0.33         9\n",
      "          62       0.06      0.29      0.10        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.27      0.60      0.37         5\n",
      "          65       1.00      0.50      0.67         2\n",
      "          66       0.85      0.85      0.85        13\n",
      "          67       0.82      0.93      0.87        15\n",
      "          68       0.30      0.38      0.33        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.50      0.79      0.61        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.45      0.31      0.37        68\n",
      "          73       0.44      0.44      0.44        18\n",
      "          74       0.15      0.21      0.17        19\n",
      "          75       0.06      0.14      0.08         7\n",
      "          76       0.22      0.40      0.29         5\n",
      "          77       0.17      0.20      0.18         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.75      1.00      0.86         3\n",
      "          80       1.00      0.25      0.40         4\n",
      "          81       0.82      0.75      0.78        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.50      0.38      0.43         8\n",
      "          84       0.33      0.67      0.44         3\n",
      "          85       0.50      0.40      0.44         5\n",
      "          86       0.90      0.69      0.78        13\n",
      "          87       0.50      0.50      0.50         6\n",
      "          88       0.67      0.33      0.44         6\n",
      "          89       1.00      0.75      0.86         4\n",
      "          90       0.83      1.00      0.91         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.50      0.50      0.50         2\n",
      "          93       1.00      0.33      0.50         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.50      1.00      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.71      1.00      0.83         5\n",
      "          98       1.00      0.50      0.67         4\n",
      "          99       1.00      1.00      1.00         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.25      0.33      0.29         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.53      0.51      0.52       102\n",
      "         104       0.56      0.59      0.57        41\n",
      "         105       0.65      0.74      0.69        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.86      0.75      0.80         8\n",
      "         108       1.00      1.00      1.00         3\n",
      "         109       0.58      0.88      0.70         8\n",
      "         110       0.33      0.33      0.33         9\n",
      "         111       0.38      0.41      0.39        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.11      0.33      0.17         3\n",
      "         114       1.00      0.80      0.89         5\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      5588\n",
      "   macro avg       0.48      0.52      0.48      5588\n",
      "weighted avg       0.55      0.48      0.50      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Use the same parameters as the previous RF model.\n",
    "RF_clf_res = RandomForestClassifier(random_state=42,\n",
    "                                max_depth = 100,\n",
    "                                min_samples_split = 2,\n",
    "                                min_samples_leaf = 2,\n",
    "                                n_estimators= 100,\n",
    "                                n_jobs = 4 \n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "RF_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "RF_y_pred_res = RF_clf_res.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(RF_y_pred_res, y_test))\n",
    "print(classification_report(y_test, RF_y_pred_res))\n",
    "rec_scores('RF_res', RF_y_pred_res)\n",
    "\n",
    "\n",
    "#Save model\n",
    "pickle.dump(RF_clf_res, open('models/RF_clf_res.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.48067287043664997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.50      0.22         2\n",
      "           1       0.96      0.96      0.96       112\n",
      "           2       0.58      0.88      0.70         8\n",
      "           3       0.68      0.72      0.70        29\n",
      "           4       0.81      0.68      0.74        19\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.20      0.61      0.30        23\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.56      0.41      0.47        46\n",
      "           9       0.76      0.71      0.73       156\n",
      "          10       0.39      0.41      0.40        29\n",
      "          11       0.33      0.50      0.40         2\n",
      "          12       0.56      0.83      0.67        12\n",
      "          13       0.27      0.31      0.29        51\n",
      "          14       0.75      0.65      0.69       215\n",
      "          15       0.38      0.44      0.40       110\n",
      "          16       0.93      0.81      0.87        16\n",
      "          17       0.27      0.20      0.23        15\n",
      "          18       1.00      0.86      0.92         7\n",
      "          19       0.62      0.61      0.61        61\n",
      "          20       0.56      0.47      0.51       534\n",
      "          21       0.08      0.14      0.11        14\n",
      "          22       0.43      0.42      0.42       210\n",
      "          23       0.86      0.95      0.90        19\n",
      "          24       0.53      0.44      0.48        45\n",
      "          25       0.25      0.18      0.21        11\n",
      "          26       0.50      0.50      0.50         8\n",
      "          27       0.60      0.30      0.40        10\n",
      "          28       0.40      0.48      0.44        25\n",
      "          29       0.43      0.86      0.57         7\n",
      "          30       0.40      0.50      0.44         4\n",
      "          31       0.56      0.52      0.54        46\n",
      "          32       0.34      0.39      0.36        31\n",
      "          33       0.09      0.11      0.10        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.23      0.22      0.22        32\n",
      "          36       0.27      0.19      0.22        16\n",
      "          37       0.50      0.86      0.63         7\n",
      "          38       0.28      0.28      0.28        67\n",
      "          39       0.31      0.42      0.35        36\n",
      "          40       0.79      0.72      0.75        32\n",
      "          41       0.50      0.31      0.38        16\n",
      "          42       0.67      0.74      0.71       210\n",
      "          43       0.47      0.38      0.42        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.25      0.33      0.29         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.42      0.52      0.46        25\n",
      "          49       0.51      0.55      0.53        91\n",
      "          50       0.50      0.50      0.50         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.58      0.65      0.61       181\n",
      "          53       0.42      0.56      0.48         9\n",
      "          54       0.33      0.37      0.35       159\n",
      "          55       0.44      0.50      0.47       536\n",
      "          56       0.30      0.36      0.33       202\n",
      "          57       0.55      0.47      0.51       829\n",
      "          58       0.44      0.24      0.31       471\n",
      "          59       0.19      0.52      0.28        66\n",
      "          60       0.02      0.04      0.03        24\n",
      "          61       0.30      0.33      0.32         9\n",
      "          62       0.16      0.24      0.19        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.50      0.20      0.29         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.92      0.85      0.88        13\n",
      "          67       0.90      0.60      0.72        15\n",
      "          68       0.55      0.38      0.44        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.79      0.79      0.79        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.43      0.37      0.40        68\n",
      "          73       0.43      0.33      0.38        18\n",
      "          74       0.18      0.16      0.17        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.27      0.60      0.37         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.27      1.00      0.43         3\n",
      "          80       1.00      0.25      0.40         4\n",
      "          81       0.58      0.58      0.58        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.36      0.50      0.42         8\n",
      "          84       0.40      0.67      0.50         3\n",
      "          85       0.50      0.20      0.29         5\n",
      "          86       0.64      0.69      0.67        13\n",
      "          87       0.80      0.67      0.73         6\n",
      "          88       0.75      0.50      0.60         6\n",
      "          89       0.75      0.75      0.75         4\n",
      "          90       1.00      0.60      0.75         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.33      0.50         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.60      0.60      0.60         5\n",
      "          98       1.00      0.25      0.40         4\n",
      "          99       1.00      0.25      0.40         4\n",
      "         100       1.00      1.00      1.00         4\n",
      "         101       0.33      0.33      0.33         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.59      0.58      0.58       102\n",
      "         104       0.33      0.59      0.42        41\n",
      "         105       0.38      0.48      0.42        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.40      0.50      0.44         8\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       0.67      0.75      0.71         8\n",
      "         110       0.29      0.22      0.25         9\n",
      "         111       0.67      0.45      0.54        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.11      0.33      0.17         3\n",
      "         114       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      5588\n",
      "   macro avg       0.45      0.43      0.42      5588\n",
      "weighted avg       0.51      0.48      0.48      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KN_clf_res = KNeighborsClassifier(n_neighbors=10, weights = 'distance', n_jobs = 4)\n",
    "\n",
    "KN_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "KN_y_pred_res = KN_clf_res.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(KN_y_pred_res, y_test))\n",
    "print(classification_report(y_test, KN_y_pred_res))\n",
    "\n",
    "rec_scores('KN_res', KN_y_pred_res)\n",
    "\n",
    "pickle.dump(KN_clf_res, open('models/KN_CV_res.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(model_scores).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Classifier Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame({'Text':X_test_desc ,'Predicted Code':le.inverse_transform(RF_y_pred), 'Actual Code':le.inverse_transform(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00-10-17</td>\n",
       "      <td>geotechnical consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-61-13</td>\n",
       "      <td>subtrade bonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-30-12</td>\n",
       "      <td>project manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-30-14</td>\n",
       "      <td>project coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-30-23</td>\n",
       "      <td>finishing superintendent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cost Code               Description\n",
       "0  00-10-17   geotechnical consultant\n",
       "1  00-61-13            subtrade bonds\n",
       "2  01-30-12           project manager\n",
       "3  01-30-14       project coordinator\n",
       "4  01-30-23  finishing superintendent"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel Surcharge</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environmental Charge</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25 MPa Footings</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Environmental charge - Applies per m3 to all c...</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polarcon Accelerating - Silver</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Predicted Code  \\\n",
       "0                                     Fuel Surcharge       03-31-43   \n",
       "1                               Environmental Charge       03-31-41   \n",
       "2                                    25 MPa Footings       03-31-40   \n",
       "3  Environmental charge - Applies per m3 to all c...       03-31-41   \n",
       "4                     Polarcon Accelerating - Silver       03-31-44   \n",
       "\n",
       "  Actual Code             Actual Code Desc.  \n",
       "0    03-31-40  concrete material - footings  \n",
       "1    03-31-40  concrete material - footings  \n",
       "2    03-31-40  concrete material - footings  \n",
       "3    03-31-40  concrete material - footings  \n",
       "4    03-31-40  concrete material - footings  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = df_output.merge(name_mapping, left_on='Actual Code',right_on='Cost Code')\n",
    "out.rename(index=str, columns={'Description':'Actual Code Desc.'}, inplace = True)\n",
    "out.drop(['Cost Code'], axis = 1, inplace = True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "      <th>Predicted Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel Surcharge</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environmental charge - Applies per m3 to all c...</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel Surcharge - Applies per load to all concrete</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FUEL SURCHARGE/CARBURANT (LD)</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FlowCrete HRWR - 110 mm Slump</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-40</td>\n",
       "      <td>concrete material - footings</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Predicted Code  \\\n",
       "0                                     Fuel Surcharge       03-31-43   \n",
       "1  Environmental charge - Applies per m3 to all c...       03-31-43   \n",
       "2  Fuel Surcharge - Applies per load to all concrete       03-31-43   \n",
       "3                      FUEL SURCHARGE/CARBURANT (LD)       03-31-43   \n",
       "4                      FlowCrete HRWR - 110 mm Slump       03-31-43   \n",
       "\n",
       "  Actual Code             Actual Code Desc.  \\\n",
       "0    03-31-40  concrete material - footings   \n",
       "1    03-31-40  concrete material - footings   \n",
       "2    03-31-40  concrete material - footings   \n",
       "3    03-31-40  concrete material - footings   \n",
       "4    03-31-40  concrete material - footings   \n",
       "\n",
       "                        Predicted Code Desc.  \n",
       "0  concrete material - above grade verticals  \n",
       "1  concrete material - above grade verticals  \n",
       "2  concrete material - above grade verticals  \n",
       "3  concrete material - above grade verticals  \n",
       "4  concrete material - above grade verticals  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.merge(name_mapping, left_on='Predicted Code',right_on='Cost Code')\n",
    "out.drop(['Cost Code'], axis = 1, inplace=True)\n",
    "out.rename(index=str, columns={'Description':'Predicted Code Desc.'}, inplace=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Text', 'Predicted Code','Predicted Code Desc.', 'Actual Code', 'Actual Code Desc.']\n",
    "out = out[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Predicted Code Desc.</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>Enviromental Levy</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>CHRONOLIA55 24HR 14MM 1-4% INTR WALLS/CLMNS</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>Andrew Johnston</td>\n",
       "      <td>01-76-20</td>\n",
       "      <td>protect finishes</td>\n",
       "      <td>01-76-20</td>\n",
       "      <td>protect finishes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>Tripod sign stand c/w flagholders</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>field supplies</td>\n",
       "      <td>01-30-31</td>\n",
       "      <td>flagperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>Fuel Surcharge - Applies per load to all concrete</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Predicted Code  \\\n",
       "1721                                  Enviromental Levy       03-31-41   \n",
       "1158        CHRONOLIA55 24HR 14MM 1-4% INTR WALLS/CLMNS       03-31-43   \n",
       "4808                                    Andrew Johnston       01-76-20   \n",
       "3245                  Tripod sign stand c/w flagholders       01-52-23   \n",
       "1575  Fuel Surcharge - Applies per load to all concrete       03-31-41   \n",
       "\n",
       "                           Predicted Code Desc. Actual Code  \\\n",
       "1721  concrete material - below-grade verticals    03-31-41   \n",
       "1158  concrete material - above grade verticals    03-31-44   \n",
       "4808                           protect finishes    01-76-20   \n",
       "3245                             field supplies    01-30-31   \n",
       "1575  concrete material - below-grade verticals    03-31-41   \n",
       "\n",
       "                                Actual Code Desc.  \n",
       "1721    concrete material - below-grade verticals  \n",
       "1158  concrete material - above grade horizontals  \n",
       "4808                             protect finishes  \n",
       "3245                                   flagperson  \n",
       "1575    concrete material - below-grade verticals  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
