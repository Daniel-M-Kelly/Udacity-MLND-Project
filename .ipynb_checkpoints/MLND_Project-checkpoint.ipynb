{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company #</th>\n",
       "      <th>Purchase Order</th>\n",
       "      <th>Item</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unit of Measure</th>\n",
       "      <th>Units</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Cost Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-001</td>\n",
       "      <td>1</td>\n",
       "      <td>Paragon Electrical Installations Ltd.</td>\n",
       "      <td>Additional smoke detector/re-verification</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>26-20-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-002</td>\n",
       "      <td>1</td>\n",
       "      <td>Accurate Aluminum Ltd</td>\n",
       "      <td>S&amp;I railing as per quote Aug. 13  2015</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>05-52-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-003</td>\n",
       "      <td>1</td>\n",
       "      <td>Dura Productions</td>\n",
       "      <td>S&amp;I metal ramp</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>05-52-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1200-004</td>\n",
       "      <td>1</td>\n",
       "      <td>Friesen Floors &amp; Window Fashions Ltd</td>\n",
       "      <td>S&amp;I hardwood flooring for enclosed balcony area</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>09-64-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1209-1-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Alba Painting Ltd.</td>\n",
       "      <td>Painting of two offices</td>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>09-91-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company # Purchase Order  Item                                 Vendor  \\\n",
       "0          8       1200-001     1  Paragon Electrical Installations Ltd.   \n",
       "1          8       1200-002     1                  Accurate Aluminum Ltd   \n",
       "2          8       1200-003     1                       Dura Productions   \n",
       "3          8       1200-004     1   Friesen Floors & Window Fashions Ltd   \n",
       "4          8      1209-1-01     1                     Alba Painting Ltd.   \n",
       "\n",
       "                                       Description Unit of Measure Units  \\\n",
       "0        Additional smoke detector/re-verification              LS     0   \n",
       "1           S&I railing as per quote Aug. 13  2015              LS     0   \n",
       "2                                   S&I metal ramp              LS     0   \n",
       "3  S&I hardwood flooring for enclosed balcony area              LS     0   \n",
       "4                          Painting of two offices              LS     0   \n",
       "\n",
       "   Unit Cost    Cost Cost Code  \n",
       "0        0.0  1444.0  26-20-20  \n",
       "1        0.0   500.0  05-52-20  \n",
       "2        0.0   795.0  05-52-20  \n",
       "3        0.0  2314.0  09-64-33  \n",
       "4        0.0   900.0  09-91-40  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data from CSV files.\n",
    "df = pd.read_csv('raw_data/PO_Dataset.csv')\n",
    "name_mapping = pd.read_csv('clean_data/Clean_Code_Master_list.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Convert the Units column to float\n",
    "df['Units'] = pd.to_numeric(df['Units'], errors='coerce').fillna(0)\n",
    "df['Units'] = df['Units'].astype('float64')\n",
    "\n",
    "#Drop lines with null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Read in Master list of valid cost codes\n",
    "df_ml = pd.read_csv('raw_data/Code_Master_list.csv')\n",
    "\n",
    "#Drop rows where the cost code is not in the master list\n",
    "df = df[df['Cost Code'].isin(df_ml['Cost Code'])].dropna()\n",
    "\n",
    "#Create a new dataframe that takes only the 90th quartile of data from the 3 numerical columns.\n",
    "df_90 = df[df['Cost'] < df['Cost'].quantile(.90)]\n",
    "df_90 = df_90[df_90['Units'] < df_90['Units'].quantile(.90)]\n",
    "df_90 = df_90[df_90['Unit Cost'] < df_90['Unit Cost'].quantile(.90)]\n",
    "\n",
    "# It's a good practice to scale numerical data\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() \n",
    "numerical = ['Units','Unit Cost','Cost']\n",
    "\n",
    "df_90[numerical] = scaler.fit_transform(df_90[numerical])\n",
    "\n",
    "# When splitting for training and testing later, we'll need a minimum of 2 examples of each cost code.\n",
    "# Assign cost code to a variable\n",
    "df_count = df_90['Cost Code'].value_counts()\n",
    "\n",
    "#New dataframe only includes lines with cost codes with a count of 10 or greater\n",
    "df_90 = df_90[~df_90['Cost Code'].isin(df_count[df_count < 10].index)]\n",
    "\n",
    "\n",
    "#One Hot Encode categorical features\n",
    "categorical = ['Vendor', 'Unit of Measure']\n",
    "df_90 = pd.get_dummies(df_90, columns = categorical )\n",
    "\n",
    "#Numerically encode cost codes.\n",
    "le = LabelEncoder()\n",
    "cost_code = df_90['Cost Code']\n",
    "df_90['Cost Code Encoded'] = le.fit_transform(cost_code)\n",
    "\n",
    "#drop features I won't be using\n",
    "df_90 = df_90.drop(['Company #','Purchase Order', 'Item'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "df = df_90\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Separate the target variable from the features\n",
    "cost_codes = df['Cost Code Encoded']\n",
    "features = df.drop(['Cost Code','Cost Code Encoded'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn train test split to split the data into training and testing sets. \n",
    "#Testing set is 20% of total dataset size.\n",
    "#Stratify the data so we don't introduce bias in the sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    cost_codes,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = cost_codes\n",
    "                                                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22349, 418)\n",
      "(22349,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Units</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Vendor_1110438 B.C. Ltd</th>\n",
       "      <th>Vendor_4s Scaffolding</th>\n",
       "      <th>Vendor_596143 BC LTD DBA AVANTE 2000</th>\n",
       "      <th>Vendor_7 Star Security Services Inc</th>\n",
       "      <th>Vendor_A &amp; A Testing Ltd.</th>\n",
       "      <th>Vendor_A Plus Cleaning and Janitorial Ltd.</th>\n",
       "      <th>...</th>\n",
       "      <th>Unit of Measure_WKS</th>\n",
       "      <th>Unit of Measure_kg</th>\n",
       "      <th>Unit of Measure_km</th>\n",
       "      <th>Unit of Measure_kw</th>\n",
       "      <th>Unit of Measure_l</th>\n",
       "      <th>Unit of Measure_m</th>\n",
       "      <th>Unit of Measure_m3</th>\n",
       "      <th>Unit of Measure_m3</th>\n",
       "      <th>Unit of Measure_mL</th>\n",
       "      <th>Unit of Measure_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24432</th>\n",
       "      <td>Garrett Patrick Doray - OT - Invoice#: 2726</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.979224</td>\n",
       "      <td>0.913882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30563</th>\n",
       "      <td>level 1 first aid kit</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.988545</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>Fuel Surcharge  $1.00/L to $1.20/L</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.979801</td>\n",
       "      <td>0.908284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38452</th>\n",
       "      <td>fuel cost recover</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.979224</td>\n",
       "      <td>0.908486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>Grinding discks</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.979566</td>\n",
       "      <td>0.909281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Description     Units  Unit Cost  \\\n",
       "24432  Garrett Patrick Doray - OT - Invoice#: 2726  0.998941   0.979224   \n",
       "30563                        level 1 first aid kit  0.999008   0.988545   \n",
       "8055            Fuel Surcharge  $1.00/L to $1.20/L  0.998974   0.979801   \n",
       "38452                            fuel cost recover  0.998941   0.979224   \n",
       "2812                               Grinding discks  0.999274   0.979566   \n",
       "\n",
       "           Cost  Vendor_1110438 B.C. Ltd  Vendor_4s Scaffolding  \\\n",
       "24432  0.913882                        0                      0   \n",
       "30563  0.914600                        0                      0   \n",
       "8055   0.908284                        0                      0   \n",
       "38452  0.908486                        0                      0   \n",
       "2812   0.909281                        0                      0   \n",
       "\n",
       "       Vendor_596143 BC LTD DBA AVANTE 2000  \\\n",
       "24432                                     0   \n",
       "30563                                     0   \n",
       "8055                                      0   \n",
       "38452                                     0   \n",
       "2812                                      0   \n",
       "\n",
       "       Vendor_7 Star Security Services Inc  Vendor_A & A Testing Ltd.  \\\n",
       "24432                                    0                          0   \n",
       "30563                                    0                          0   \n",
       "8055                                     0                          0   \n",
       "38452                                    0                          0   \n",
       "2812                                     0                          0   \n",
       "\n",
       "       Vendor_A Plus Cleaning and Janitorial Ltd.        ...          \\\n",
       "24432                                           0        ...           \n",
       "30563                                           0        ...           \n",
       "8055                                            0        ...           \n",
       "38452                                           0        ...           \n",
       "2812                                            0        ...           \n",
       "\n",
       "       Unit of Measure_WKS  Unit of Measure_kg  Unit of Measure_km  \\\n",
       "24432                    0                   0                   0   \n",
       "30563                    0                   0                   0   \n",
       "8055                     0                   0                   0   \n",
       "38452                    0                   0                   0   \n",
       "2812                     0                   0                   0   \n",
       "\n",
       "       Unit of Measure_kw  Unit of Measure_l  Unit of Measure_m  \\\n",
       "24432                   0                  0                  0   \n",
       "30563                   0                  0                  0   \n",
       "8055                    0                  0                  0   \n",
       "38452                   0                  0                  0   \n",
       "2812                    0                  0                  0   \n",
       "\n",
       "       Unit of Measure_m3  Unit of Measure_m3   Unit of Measure_mL  \\\n",
       "24432                   0                    0                   0   \n",
       "30563                   0                    0                   0   \n",
       "8055                    0                    0                   0   \n",
       "38452                   0                    0                   0   \n",
       "2812                    0                    0                   0   \n",
       "\n",
       "       Unit of Measure_t  \n",
       "24432                  0  \n",
       "30563                  0  \n",
       "8055                   0  \n",
       "38452                  0  \n",
       "2812                   0  \n",
       "\n",
       "[5 rows x 418 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm the number of samples in X and y training data are the same\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split out X_train and X_test Descriptions for use in sepearate model.\n",
    "X_train_desc = X_train['Description'].copy()\n",
    "X_train = X_train.drop('Description', axis=1)\n",
    "\n",
    "X_test_desc = X_test['Description'].copy()\n",
    "X_test = X_test.drop('Description', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    2.4s remaining:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.4141673007296125\n",
      "{'clf__alpha': 0.0001, 'clf__max_iter': 20, 'clf__penalty': 'l2'}\n",
      "\n",
      " Test output\n",
      "accuracy 44.1124%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.87      0.98      0.92       112\n",
      "           2       0.57      1.00      0.73         8\n",
      "           3       0.84      0.55      0.67        29\n",
      "           4       0.81      0.89      0.85        19\n",
      "           5       0.67      0.80      0.73         5\n",
      "           6       0.46      0.48      0.47        23\n",
      "           7       0.50      0.40      0.44         5\n",
      "           8       0.45      0.30      0.36        46\n",
      "           9       0.68      0.77      0.72       156\n",
      "          10       0.24      0.41      0.31        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.13      0.33      0.19        12\n",
      "          13       0.43      0.25      0.32        51\n",
      "          14       0.60      0.79      0.68       215\n",
      "          15       0.38      0.16      0.23       110\n",
      "          16       0.69      0.56      0.62        16\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.71      0.71      0.71         7\n",
      "          19       0.52      0.41      0.46        61\n",
      "          20       0.37      0.59      0.46       534\n",
      "          21       0.33      0.07      0.12        14\n",
      "          22       0.44      0.36      0.40       210\n",
      "          23       0.76      1.00      0.86        19\n",
      "          24       0.56      0.33      0.42        45\n",
      "          25       0.33      0.18      0.24        11\n",
      "          26       1.00      0.62      0.77         8\n",
      "          27       0.50      0.10      0.17        10\n",
      "          28       0.50      0.40      0.44        25\n",
      "          29       0.00      0.00      0.00         7\n",
      "          30       1.00      0.25      0.40         4\n",
      "          31       0.53      0.39      0.45        46\n",
      "          32       0.50      0.35      0.42        31\n",
      "          33       0.17      0.05      0.08        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.35      0.28      0.31        32\n",
      "          36       0.67      0.12      0.21        16\n",
      "          37       0.40      0.29      0.33         7\n",
      "          38       0.23      0.09      0.13        67\n",
      "          39       0.40      0.17      0.24        36\n",
      "          40       0.51      0.69      0.59        32\n",
      "          41       0.29      0.25      0.27        16\n",
      "          42       0.65      0.71      0.68       210\n",
      "          43       0.47      0.28      0.35        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.25      0.17      0.20         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.11      0.28      0.15        25\n",
      "          49       0.44      0.35      0.39        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.37      0.50      0.43       181\n",
      "          53       0.67      0.22      0.33         9\n",
      "          54       0.26      0.18      0.21       159\n",
      "          55       0.37      0.38      0.37       536\n",
      "          56       0.29      0.28      0.28       202\n",
      "          57       0.45      0.63      0.52       829\n",
      "          58       0.35      0.08      0.14       471\n",
      "          59       0.55      0.32      0.40        66\n",
      "          60       0.50      0.08      0.14        24\n",
      "          61       0.25      0.22      0.24         9\n",
      "          62       0.04      0.08      0.06        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.25      0.20      0.22         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.67      0.92      0.77        13\n",
      "          67       0.73      0.73      0.73        15\n",
      "          68       0.70      0.44      0.54        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.48      0.53      0.50        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.42      0.35      0.38        68\n",
      "          73       0.56      0.28      0.37        18\n",
      "          74       0.29      0.11      0.15        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       0.80      0.33      0.47        12\n",
      "          82       1.00      0.50      0.67         2\n",
      "          83       0.60      0.75      0.67         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       1.00      0.40      0.57         5\n",
      "          86       0.80      0.62      0.70        13\n",
      "          87       0.50      0.33      0.40         6\n",
      "          88       0.38      0.50      0.43         6\n",
      "          89       1.00      0.50      0.67         4\n",
      "          90       1.00      0.20      0.33         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.40      0.33      0.36         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       0.20      0.25      0.22         4\n",
      "          99       0.00      0.00      0.00         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       1.00      0.17      0.29         6\n",
      "         102       0.04      0.20      0.07         5\n",
      "         103       0.54      0.56      0.55       102\n",
      "         104       0.52      0.34      0.41        41\n",
      "         105       0.11      0.22      0.14        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.67      0.25      0.36         8\n",
      "         108       0.00      0.00      0.00         3\n",
      "         109       0.40      0.50      0.44         8\n",
      "         110       0.40      0.22      0.29         9\n",
      "         111       0.64      0.32      0.42        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       0.50      0.20      0.29         5\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      5588\n",
      "   macro avg       0.40      0.31      0.32      5588\n",
      "weighted avg       0.44      0.44      0.42      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Create a pipeline for vectorizing the description text and calculating the tfidf value, then traom the SGDClassifier\n",
    "\n",
    "SGDC_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(random_state=42, tol = 1e-3)),\n",
    "               ])\n",
    "\n",
    "#Configure the parameters to iterate through\n",
    "parameters = {\n",
    "    #'clf__loss':['hinge','log'],\n",
    "    #'clf__penalty':['l1','l2'],\n",
    "    #'clf__alpha':[1e-3,1e-4],\n",
    "    #'clf__max_iter':[15,20,25]\n",
    "    'clf__penalty':['l2'],\n",
    "    'clf__alpha':[1e-4],\n",
    "    'clf__max_iter':[20]\n",
    "}\n",
    "\n",
    "\n",
    "#Configure Gridsearch cross validation\n",
    "SGDC_CV = GridSearchCV(SGDC_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "#Fit the model and execute the gridsearch\n",
    "SGDC_CV.fit(X_train_desc, y_train)\n",
    "\n",
    "#Print the \n",
    "print('Best score and parameter combination = ')\n",
    "print(SGDC_CV.best_score_)    \n",
    "print(SGDC_CV.best_params_) \n",
    "\n",
    "\n",
    "SGDC_y_pred = SGDC_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(SGDC_y_pred, y_test)))\n",
    "print(classification_report(y_test, SGDC_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(SGDC_CV, open('models/SGDC_CV.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    3.2s remaining:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.4436033402638951\n",
      "{'clf__C': 10, 'clf__max_iter': 100, 'clf__solver': 'saga', 'clf__tol': 0.01}\n",
      "\n",
      " Test output\n",
      "accuracy 48.7473%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.93      0.96      0.95       112\n",
      "           2       0.67      1.00      0.80         8\n",
      "           3       0.85      0.59      0.69        29\n",
      "           4       0.85      0.89      0.87        19\n",
      "           5       0.75      0.60      0.67         5\n",
      "           6       0.56      0.61      0.58        23\n",
      "           7       0.50      0.40      0.44         5\n",
      "           8       0.45      0.33      0.38        46\n",
      "           9       0.61      0.88      0.72       156\n",
      "          10       0.47      0.24      0.32        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.67      0.50      0.57        12\n",
      "          13       0.42      0.27      0.33        51\n",
      "          14       0.68      0.76      0.72       215\n",
      "          15       0.46      0.32      0.38       110\n",
      "          16       0.90      0.56      0.69        16\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       1.00      0.57      0.73         7\n",
      "          19       0.60      0.39      0.48        61\n",
      "          20       0.37      0.69      0.48       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.42      0.41      0.41       210\n",
      "          23       1.00      1.00      1.00        19\n",
      "          24       0.64      0.31      0.42        45\n",
      "          25       0.38      0.27      0.32        11\n",
      "          26       0.71      0.62      0.67         8\n",
      "          27       0.50      0.20      0.29        10\n",
      "          28       0.39      0.48      0.43        25\n",
      "          29       0.00      0.00      0.00         7\n",
      "          30       1.00      0.25      0.40         4\n",
      "          31       0.50      0.41      0.45        46\n",
      "          32       0.53      0.32      0.40        31\n",
      "          33       0.25      0.05      0.09        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.73      0.34      0.47        32\n",
      "          36       0.67      0.12      0.21        16\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.29      0.13      0.18        67\n",
      "          39       0.67      0.22      0.33        36\n",
      "          40       0.67      0.69      0.68        32\n",
      "          41       0.33      0.25      0.29        16\n",
      "          42       0.65      0.72      0.68       210\n",
      "          43       0.67      0.38      0.48        53\n",
      "          44       1.00      0.50      0.67         2\n",
      "          45       0.33      0.17      0.22         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.67      0.24      0.35        25\n",
      "          49       0.49      0.31      0.38        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.66      0.54      0.59       181\n",
      "          53       0.75      0.33      0.46         9\n",
      "          54       0.75      0.11      0.20       159\n",
      "          55       0.42      0.50      0.45       536\n",
      "          56       0.76      0.19      0.31       202\n",
      "          57       0.43      0.75      0.55       829\n",
      "          58       0.40      0.12      0.19       471\n",
      "          59       0.39      0.36      0.38        66\n",
      "          60       0.00      0.00      0.00        24\n",
      "          61       0.25      0.11      0.15         9\n",
      "          62       0.25      0.03      0.05        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.50      0.20      0.29         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.60      0.69      0.64        13\n",
      "          67       0.83      0.67      0.74        15\n",
      "          68       0.82      0.56      0.67        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.61      0.58      0.59        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.49      0.38      0.43        68\n",
      "          73       0.50      0.39      0.44        18\n",
      "          74       0.12      0.05      0.07        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       1.00      0.25      0.40        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.71      0.62      0.67         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       1.00      0.20      0.33         5\n",
      "          86       0.80      0.62      0.70        13\n",
      "          87       0.50      0.33      0.40         6\n",
      "          88       0.60      0.50      0.55         6\n",
      "          89       1.00      0.25      0.40         4\n",
      "          90       1.00      0.40      0.57         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.33      0.50         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       1.00      0.25      0.40         4\n",
      "          99       0.00      0.00      0.00         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       1.00      0.17      0.29         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.56      0.60      0.58       102\n",
      "         104       0.54      0.34      0.42        41\n",
      "         105       0.23      0.22      0.22        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.50      0.25      0.33         8\n",
      "         108       0.00      0.00      0.00         3\n",
      "         109       0.57      0.50      0.53         8\n",
      "         110       0.50      0.44      0.47         9\n",
      "         111       0.70      0.32      0.44        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.20      0.33         5\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      5588\n",
      "   macro avg       0.46      0.31      0.34      5588\n",
      "weighted avg       0.51      0.49      0.46      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(random_state=42,multi_class='multinomial')),\n",
    "               ])\n",
    "parameters = {\n",
    "    'clf__C':[10],\n",
    "    'clf__solver':['saga'],\n",
    "    'clf__max_iter':[100],\n",
    "    'clf__tol': [0.01]\n",
    "}\n",
    "\n",
    "#Weighted F1 score takes into account the imbalance of the classes\n",
    "LR_CV = GridSearchCV(LR_pipeline, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose=5)\n",
    "\n",
    "LR_CV.fit(X_train_desc, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(LR_CV.best_score_)    \n",
    "print(LR_CV.best_params_) \n",
    "\n",
    "\n",
    "LR_y_pred = LR_CV.predict(X_test_desc)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(LR_y_pred, y_test)))\n",
    "print(classification_report(y_test, LR_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(LR_CV, open('models/LR_CV.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Logistic Regression model had the best accuracy, load the model saved to file\n",
    "LR_CV = pickle.load(open('models/LR_CV.sav', 'rb'))\n",
    "\n",
    "\n",
    "# Append its prediction to the training and testing datasets to create a new feature\n",
    "X_train['Desc Pred'] = LR_CV.predict(X_train_desc)\n",
    "X_test['Desc Pred'] = LR_CV.predict(X_test_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  1.4min remaining:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.5475785541434021\n",
      "{'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 700}\n",
      "\n",
      " Test output\n",
      "accuracy 53.4180%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.87      0.96      0.91       112\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       0.80      0.55      0.65        29\n",
      "           4       0.88      0.79      0.83        19\n",
      "           5       1.00      0.60      0.75         5\n",
      "           6       0.83      0.22      0.34        23\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.58      0.39      0.47        46\n",
      "           9       0.72      0.79      0.75       156\n",
      "          10       0.80      0.28      0.41        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.86      0.50      0.63        12\n",
      "          13       0.63      0.24      0.34        51\n",
      "          14       0.74      0.77      0.76       215\n",
      "          15       0.56      0.44      0.49       110\n",
      "          16       1.00      0.94      0.97        16\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.86      0.86      0.86         7\n",
      "          19       0.83      0.49      0.62        61\n",
      "          20       0.38      0.81      0.51       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.46      0.45      0.45       210\n",
      "          23       0.90      1.00      0.95        19\n",
      "          24       0.63      0.27      0.38        45\n",
      "          25       0.20      0.18      0.19        11\n",
      "          26       0.75      0.38      0.50         8\n",
      "          27       0.60      0.30      0.40        10\n",
      "          28       0.38      0.40      0.39        25\n",
      "          29       0.50      0.57      0.53         7\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.91      0.43      0.59        46\n",
      "          32       0.25      0.10      0.14        31\n",
      "          33       0.33      0.05      0.09        19\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.70      0.22      0.33        32\n",
      "          36       0.36      0.25      0.30        16\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.45      0.15      0.22        67\n",
      "          39       0.88      0.19      0.32        36\n",
      "          40       0.91      0.94      0.92        32\n",
      "          41       0.83      0.31      0.45        16\n",
      "          42       0.59      0.72      0.65       210\n",
      "          43       0.75      0.34      0.47        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.44      0.32      0.37        25\n",
      "          49       0.67      0.46      0.55        91\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.87      0.56      0.68       181\n",
      "          53       1.00      0.33      0.50         9\n",
      "          54       0.71      0.26      0.39       159\n",
      "          55       0.50      0.54      0.52       536\n",
      "          56       0.72      0.28      0.40       202\n",
      "          57       0.46      0.79      0.58       829\n",
      "          58       0.53      0.27      0.36       471\n",
      "          59       0.81      0.26      0.39        66\n",
      "          60       1.00      0.04      0.08        24\n",
      "          61       0.50      0.11      0.18         9\n",
      "          62       1.00      0.05      0.10        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       1.00      0.20      0.33         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.67      0.62      0.64        13\n",
      "          67       0.81      0.87      0.84        15\n",
      "          68       0.78      0.44      0.56        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.71      0.53      0.61        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.43      0.38      0.41        68\n",
      "          73       0.40      0.22      0.29        18\n",
      "          74       0.09      0.05      0.07        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.67      0.50      0.57         4\n",
      "          81       0.83      0.42      0.56        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.80      0.50      0.62         8\n",
      "          84       1.00      0.33      0.50         3\n",
      "          85       1.00      0.20      0.33         5\n",
      "          86       1.00      0.62      0.76        13\n",
      "          87       1.00      0.17      0.29         6\n",
      "          88       0.83      0.83      0.83         6\n",
      "          89       1.00      0.50      0.67         4\n",
      "          90       0.50      0.20      0.29         5\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.17      0.29         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       1.00      0.25      0.40         4\n",
      "          99       1.00      0.50      0.67         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       0.00      0.00      0.00         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.61      0.59      0.60       102\n",
      "         104       0.67      0.39      0.49        41\n",
      "         105       0.59      0.43      0.50        23\n",
      "         106       1.00      0.67      0.80         3\n",
      "         107       1.00      0.50      0.67         8\n",
      "         108       1.00      0.33      0.50         3\n",
      "         109       0.80      0.50      0.62         8\n",
      "         110       1.00      0.22      0.36         9\n",
      "         111       0.45      0.45      0.45        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       1.00      0.20      0.33         5\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      5588\n",
      "   macro avg       0.53      0.32      0.37      5588\n",
      "weighted avg       0.58      0.53      0.51      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Try a random forest ensemble classifier to evaluate the numeric features plus the predicted feature\n",
    "RF_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "parameters = {'max_depth': [100],\n",
    "              'min_samples_split': [2],\n",
    "              'min_samples_leaf': [2],\n",
    "              'n_estimators': [700]\n",
    "             }\n",
    "\n",
    "RF_CV = GridSearchCV(RF_clf, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "RF_CV.fit(X_train, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(RF_CV.best_score_)    \n",
    "print(RF_CV.best_params_) \n",
    "\n",
    "\n",
    "RF_y_pred = RF_CV.predict(X_test)\n",
    "\n",
    "print('\\n Test output')\n",
    "print('accuracy {:.4f}%'.format(100*accuracy_score(RF_y_pred, y_test)))\n",
    "print(classification_report(y_test, RF_y_pred))\n",
    "\n",
    "#Save model\n",
    "pickle.dump(RF_CV, open('models/RF_CV.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {}\n",
    "\n",
    "def rec_scores(name, y_pred):\n",
    "\n",
    "    model_scores[name] = classification_report(y_test, y_pred, output_dict=True)['weighted avg']\n",
    "    model_scores[name]['accuracy'] = accuracy_score(y_pred, y_test)\n",
    "    model_scores[name].pop('support',None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rec_scores('RF', RF_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a17ea3c50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What do the feature importances look like?\n",
    "(pd.Series(RF_CV.best_estimator_.feature_importances_, index=X_train.columns).nlargest(4).plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   44.3s remaining:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination = \n",
      "0.6263757299702242\n",
      "{'n_neighbors': 10, 'weights': 'distance'}\n",
      "accuracy 0.5214745884037223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.92      0.96      0.94       112\n",
      "           2       0.67      1.00      0.80         8\n",
      "           3       0.78      0.62      0.69        29\n",
      "           4       0.81      0.89      0.85        19\n",
      "           5       1.00      0.60      0.75         5\n",
      "           6       0.44      0.65      0.53        23\n",
      "           7       0.50      0.40      0.44         5\n",
      "           8       0.63      0.41      0.50        46\n",
      "           9       0.73      0.79      0.76       156\n",
      "          10       0.41      0.45      0.43        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.70      0.58      0.64        12\n",
      "          13       0.33      0.29      0.31        51\n",
      "          14       0.72      0.75      0.73       215\n",
      "          15       0.48      0.49      0.49       110\n",
      "          16       1.00      0.62      0.77        16\n",
      "          17       0.40      0.13      0.20        15\n",
      "          18       1.00      0.57      0.73         7\n",
      "          19       0.58      0.52      0.55        61\n",
      "          20       0.46      0.65      0.54       534\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.41      0.48      0.44       210\n",
      "          23       0.95      1.00      0.97        19\n",
      "          24       0.51      0.42      0.46        45\n",
      "          25       0.33      0.27      0.30        11\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       0.43      0.30      0.35        10\n",
      "          28       0.31      0.44      0.37        25\n",
      "          29       0.22      0.29      0.25         7\n",
      "          30       0.50      0.25      0.33         4\n",
      "          31       0.55      0.46      0.50        46\n",
      "          32       0.33      0.19      0.24        31\n",
      "          33       0.17      0.05      0.08        19\n",
      "          34       0.33      0.33      0.33         3\n",
      "          35       0.48      0.34      0.40        32\n",
      "          36       0.45      0.31      0.37        16\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.26      0.22      0.24        67\n",
      "          39       0.48      0.33      0.39        36\n",
      "          40       0.69      0.69      0.69        32\n",
      "          41       0.47      0.50      0.48        16\n",
      "          42       0.66      0.73      0.70       210\n",
      "          43       0.61      0.38      0.47        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.25      0.17      0.20         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.35      0.24      0.29        25\n",
      "          49       0.51      0.44      0.47        91\n",
      "          50       1.00      0.50      0.67         2\n",
      "          51       0.67      0.40      0.50         5\n",
      "          52       0.64      0.61      0.62       181\n",
      "          53       0.56      0.56      0.56         9\n",
      "          54       0.50      0.35      0.41       159\n",
      "          55       0.46      0.51      0.48       536\n",
      "          56       0.47      0.36      0.41       202\n",
      "          57       0.51      0.61      0.56       829\n",
      "          58       0.37      0.35      0.36       471\n",
      "          59       0.61      0.30      0.40        66\n",
      "          60       0.50      0.08      0.14        24\n",
      "          61       0.50      0.22      0.31         9\n",
      "          62       0.47      0.24      0.32        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.75      0.60      0.67         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.67      0.77      0.71        13\n",
      "          67       0.77      0.67      0.71        15\n",
      "          68       0.82      0.56      0.67        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.86      0.63      0.73        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.45      0.37      0.41        68\n",
      "          73       0.47      0.39      0.42        18\n",
      "          74       0.27      0.16      0.20        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       0.71      0.42      0.53        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.71      0.62      0.67         8\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       1.00      0.60      0.75         5\n",
      "          86       0.82      0.69      0.75        13\n",
      "          87       0.67      0.33      0.44         6\n",
      "          88       0.60      0.50      0.55         6\n",
      "          89       1.00      0.25      0.40         4\n",
      "          90       1.00      0.40      0.57         5\n",
      "          91       0.25      0.20      0.22         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.33      0.50         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       1.00      0.20      0.33         5\n",
      "          98       0.50      0.25      0.33         4\n",
      "          99       0.50      0.25      0.33         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       1.00      0.17      0.29         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.58      0.65      0.61       102\n",
      "         104       0.45      0.41      0.43        41\n",
      "         105       0.64      0.39      0.49        23\n",
      "         106       0.60      1.00      0.75         3\n",
      "         107       1.00      0.25      0.40         8\n",
      "         108       0.00      0.00      0.00         3\n",
      "         109       0.62      0.62      0.62         8\n",
      "         110       0.67      0.67      0.67         9\n",
      "         111       0.50      0.55      0.52        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       1.00      0.33      0.50         3\n",
      "         114       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5588\n",
      "   macro avg       0.49      0.37      0.41      5588\n",
      "weighted avg       0.52      0.52      0.51      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Try the KNeighborsClassifier \n",
    "KN_clf = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [10],\n",
    "              'weights': ['distance']\n",
    "             }\n",
    "\n",
    "KN_CV = GridSearchCV(KN_clf, parameters, scoring = 'f1_weighted', n_jobs=4, cv = 5, verbose = 5)\n",
    "\n",
    "KN_CV.fit(X_train, y_train)\n",
    "print('Best score and parameter combination = ')\n",
    "print(KN_CV.best_score_)    \n",
    "print(KN_CV.best_params_) \n",
    "\n",
    "\n",
    "KN_y_pred = KN_CV.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(KN_y_pred, y_test))\n",
    "print(classification_report(y_test, KN_y_pred))\n",
    "rec_scores('KN', KN_y_pred)\n",
    "\n",
    "#Save model\n",
    "pickle.dump(KN_CV, open('models/KN_CV.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SMOTE oversampling to the training dataset to to reduce bias introduced by the imbalanced dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train,y_train.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380995"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How big is the training set now?\n",
    "len(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4763779527559055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.95      0.96      0.96       112\n",
      "           2       0.80      1.00      0.89         8\n",
      "           3       0.70      0.66      0.68        29\n",
      "           4       0.89      0.89      0.89        19\n",
      "           5       0.60      0.60      0.60         5\n",
      "           6       0.71      0.43      0.54        23\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.54      0.43      0.48        46\n",
      "           9       0.79      0.76      0.77       156\n",
      "          10       0.38      0.52      0.43        29\n",
      "          11       1.00      0.50      0.67         2\n",
      "          12       0.78      0.58      0.67        12\n",
      "          13       0.24      0.33      0.28        51\n",
      "          14       0.80      0.78      0.79       215\n",
      "          15       0.51      0.47      0.49       110\n",
      "          16       0.88      0.94      0.91        16\n",
      "          17       0.20      0.20      0.20        15\n",
      "          18       0.75      0.86      0.80         7\n",
      "          19       0.63      0.54      0.58        61\n",
      "          20       0.58      0.39      0.46       534\n",
      "          21       0.07      0.14      0.09        14\n",
      "          22       0.46      0.40      0.43       210\n",
      "          23       0.83      1.00      0.90        19\n",
      "          24       0.32      0.44      0.37        45\n",
      "          25       0.31      0.45      0.37        11\n",
      "          26       0.31      0.50      0.38         8\n",
      "          27       0.29      0.50      0.37        10\n",
      "          28       0.37      0.52      0.43        25\n",
      "          29       0.45      0.71      0.56         7\n",
      "          30       0.07      0.50      0.12         4\n",
      "          31       0.60      0.54      0.57        46\n",
      "          32       0.25      0.19      0.22        31\n",
      "          33       0.12      0.16      0.14        19\n",
      "          34       0.03      1.00      0.05         3\n",
      "          35       0.32      0.38      0.35        32\n",
      "          36       0.28      0.56      0.38        16\n",
      "          37       0.20      0.14      0.17         7\n",
      "          38       0.26      0.15      0.19        67\n",
      "          39       0.38      0.33      0.35        36\n",
      "          40       0.83      0.94      0.88        32\n",
      "          41       0.92      0.75      0.83        16\n",
      "          42       0.77      0.62      0.69       210\n",
      "          43       0.55      0.42      0.47        53\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.08      0.17      0.11         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.34      0.40      0.37        25\n",
      "          49       0.51      0.60      0.56        91\n",
      "          50       0.33      1.00      0.50         2\n",
      "          51       1.00      0.20      0.33         5\n",
      "          52       0.74      0.59      0.66       181\n",
      "          53       0.38      0.67      0.48         9\n",
      "          54       0.29      0.37      0.32       159\n",
      "          55       0.49      0.43      0.46       536\n",
      "          56       0.40      0.50      0.44       202\n",
      "          57       0.59      0.37      0.45       829\n",
      "          58       0.39      0.38      0.38       471\n",
      "          59       0.21      0.50      0.29        66\n",
      "          60       0.07      0.12      0.09        24\n",
      "          61       0.40      0.22      0.29         9\n",
      "          62       0.09      0.45      0.14        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.27      0.80      0.40         5\n",
      "          65       0.33      0.50      0.40         2\n",
      "          66       0.67      0.92      0.77        13\n",
      "          67       0.81      0.87      0.84        15\n",
      "          68       0.43      0.62      0.51        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.56      0.74      0.64        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.40      0.32      0.36        68\n",
      "          73       0.35      0.44      0.39        18\n",
      "          74       0.12      0.26      0.16        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.25      0.40      0.31         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.67      0.67      0.67         3\n",
      "          80       0.50      0.75      0.60         4\n",
      "          81       0.70      0.58      0.64        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.83      0.62      0.71         8\n",
      "          84       0.43      1.00      0.60         3\n",
      "          85       0.75      0.60      0.67         5\n",
      "          86       1.00      0.69      0.82        13\n",
      "          87       1.00      0.50      0.67         6\n",
      "          88       0.80      0.67      0.73         6\n",
      "          89       1.00      0.50      0.67         4\n",
      "          90       0.60      0.60      0.60         5\n",
      "          91       0.10      0.20      0.13         5\n",
      "          92       1.00      0.50      0.67         2\n",
      "          93       0.71      0.83      0.77         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       0.33      0.50      0.40         2\n",
      "          97       0.56      1.00      0.71         5\n",
      "          98       1.00      0.25      0.40         4\n",
      "          99       1.00      0.75      0.86         4\n",
      "         100       1.00      0.75      0.86         4\n",
      "         101       0.33      0.17      0.22         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.63      0.57      0.60       102\n",
      "         104       0.39      0.46      0.42        41\n",
      "         105       0.57      0.52      0.55        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.62      0.62      0.62         8\n",
      "         108       0.75      1.00      0.86         3\n",
      "         109       0.86      0.75      0.80         8\n",
      "         110       0.50      0.33      0.40         9\n",
      "         111       0.35      0.50      0.42        22\n",
      "         112       0.08      0.33      0.12         3\n",
      "         113       0.25      0.67      0.36         3\n",
      "         114       1.00      0.80      0.89         5\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      5588\n",
      "   macro avg       0.48      0.50      0.47      5588\n",
      "weighted avg       0.53      0.48      0.49      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Use the same parameters as the previous RF model.\n",
    "RF_clf_res = RandomForestClassifier(random_state=42,\n",
    "                                max_depth = 100,\n",
    "                                min_samples_split = 2,\n",
    "                                min_samples_leaf = 2,\n",
    "                                n_estimators= 100,\n",
    "                                n_jobs = 4 \n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "RF_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "RF_y_pred_res = RF_clf_res.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(RF_y_pred_res, y_test))\n",
    "print(classification_report(y_test, RF_y_pred_res))\n",
    "rec_scores('RF_res', RF_y_pred_res)\n",
    "\n",
    "\n",
    "#Save model\n",
    "pickle.dump(RF_clf_res, open('models/RF_clf_res.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.47619899785254116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.94      0.96      0.95       112\n",
      "           2       0.80      1.00      0.89         8\n",
      "           3       0.67      0.62      0.64        29\n",
      "           4       0.81      0.89      0.85        19\n",
      "           5       0.60      0.60      0.60         5\n",
      "           6       0.71      0.65      0.68        23\n",
      "           7       0.67      0.80      0.73         5\n",
      "           8       0.63      0.41      0.50        46\n",
      "           9       0.78      0.75      0.76       156\n",
      "          10       0.37      0.48      0.42        29\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.58      0.58      0.58        12\n",
      "          13       0.27      0.29      0.28        51\n",
      "          14       0.77      0.72      0.74       215\n",
      "          15       0.46      0.48      0.47       110\n",
      "          16       1.00      0.62      0.77        16\n",
      "          17       0.14      0.20      0.17        15\n",
      "          18       1.00      0.57      0.73         7\n",
      "          19       0.47      0.52      0.50        61\n",
      "          20       0.55      0.43      0.48       534\n",
      "          21       0.04      0.07      0.05        14\n",
      "          22       0.45      0.45      0.45       210\n",
      "          23       1.00      1.00      1.00        19\n",
      "          24       0.28      0.47      0.35        45\n",
      "          25       0.22      0.36      0.28        11\n",
      "          26       0.55      0.75      0.63         8\n",
      "          27       0.30      0.30      0.30        10\n",
      "          28       0.33      0.52      0.40        25\n",
      "          29       0.29      0.57      0.38         7\n",
      "          30       0.25      0.25      0.25         4\n",
      "          31       0.46      0.48      0.47        46\n",
      "          32       0.27      0.23      0.25        31\n",
      "          33       0.10      0.16      0.12        19\n",
      "          34       0.08      0.67      0.15         3\n",
      "          35       0.45      0.41      0.43        32\n",
      "          36       0.29      0.25      0.27        16\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.25      0.21      0.23        67\n",
      "          39       0.33      0.42      0.37        36\n",
      "          40       0.67      0.75      0.71        32\n",
      "          41       0.50      0.56      0.53        16\n",
      "          42       0.67      0.70      0.69       210\n",
      "          43       0.59      0.42      0.49        53\n",
      "          44       0.50      0.50      0.50         2\n",
      "          45       0.17      0.17      0.17         6\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.47      0.36      0.41        25\n",
      "          49       0.49      0.45      0.47        91\n",
      "          50       0.40      1.00      0.57         2\n",
      "          51       0.50      0.40      0.44         5\n",
      "          52       0.60      0.64      0.62       181\n",
      "          53       0.36      0.56      0.43         9\n",
      "          54       0.34      0.33      0.34       159\n",
      "          55       0.48      0.39      0.43       536\n",
      "          56       0.29      0.53      0.38       202\n",
      "          57       0.56      0.41      0.47       829\n",
      "          58       0.36      0.42      0.39       471\n",
      "          59       0.32      0.35      0.34        66\n",
      "          60       0.09      0.17      0.11        24\n",
      "          61       0.11      0.22      0.15         9\n",
      "          62       0.24      0.37      0.29        38\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.23      0.60      0.33         5\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.67      0.77      0.71        13\n",
      "          67       0.83      0.67      0.74        15\n",
      "          68       0.50      0.56      0.53        16\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.86      0.63      0.73        19\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.38      0.35      0.37        68\n",
      "          73       0.41      0.39      0.40        18\n",
      "          74       0.06      0.11      0.07        19\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       1.00      0.67      0.80         3\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       0.45      0.42      0.43        12\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.62      0.62      0.62         8\n",
      "          84       0.50      0.33      0.40         3\n",
      "          85       0.80      0.80      0.80         5\n",
      "          86       0.82      0.69      0.75        13\n",
      "          87       0.50      0.50      0.50         6\n",
      "          88       0.60      0.50      0.55         6\n",
      "          89       1.00      0.25      0.40         4\n",
      "          90       0.67      0.40      0.50         5\n",
      "          91       0.10      0.20      0.13         5\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       1.00      0.33      0.50         6\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.50      0.20      0.29         5\n",
      "          98       1.00      0.25      0.40         4\n",
      "          99       0.67      0.50      0.57         4\n",
      "         100       0.75      0.75      0.75         4\n",
      "         101       0.33      0.17      0.22         6\n",
      "         102       0.00      0.00      0.00         5\n",
      "         103       0.61      0.64      0.62       102\n",
      "         104       0.36      0.41      0.39        41\n",
      "         105       0.56      0.39      0.46        23\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       0.71      0.62      0.67         8\n",
      "         108       0.00      0.00      0.00         3\n",
      "         109       0.62      0.62      0.62         8\n",
      "         110       0.35      0.78      0.48         9\n",
      "         111       0.46      0.55      0.50        22\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.06      0.33      0.10         3\n",
      "         114       0.22      0.40      0.29         5\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      5588\n",
      "   macro avg       0.43      0.42      0.40      5588\n",
      "weighted avg       0.50      0.48      0.48      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/danielkelly/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KN_clf_res = KNeighborsClassifier(n_neighbors=10, weights = 'distance', n_jobs = 4)\n",
    "\n",
    "KN_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "KN_y_pred_res = KN_clf_res.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(KN_y_pred_res, y_test))\n",
    "print(classification_report(y_test, KN_y_pred_res))\n",
    "\n",
    "rec_scores('KN_res', KN_y_pred_res)\n",
    "\n",
    "pickle.dump(KN_clf_res, open('models/KN_CV_res.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(model_scores).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Classifier Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame({'Text':X_test_desc ,'Predicted Code':le.inverse_transform(RF_y_pred), 'Actual Code':le.inverse_transform(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00-10-17</td>\n",
       "      <td>geotechnical consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-61-13</td>\n",
       "      <td>subtrade bonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-30-12</td>\n",
       "      <td>project manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-30-14</td>\n",
       "      <td>project coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-30-23</td>\n",
       "      <td>finishing superintendent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cost Code               Description\n",
       "0  00-10-17   geotechnical consultant\n",
       "1  00-61-13            subtrade bonds\n",
       "2  01-30-12           project manager\n",
       "3  01-30-14       project coordinator\n",
       "4  01-30-23  finishing superintendent"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel Surcharge</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuel Surcharge - Applies per load to all concrete</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overtime - Applies to 7:00am and after 5:00pm</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ultra Series Flow1-110mm</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35MPA  &lt;4% 20mm</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Predicted Code  \\\n",
       "0                                     Fuel Surcharge       03-31-43   \n",
       "1  Fuel Surcharge - Applies per load to all concrete       03-31-43   \n",
       "2      Overtime - Applies to 7:00am and after 5:00pm       03-31-43   \n",
       "3                           Ultra Series Flow1-110mm       03-31-43   \n",
       "4                                    35MPA  <4% 20mm       03-31-44   \n",
       "\n",
       "  Actual Code                            Actual Code Desc.  \n",
       "0    03-31-44  concrete material - above grade horizontals  \n",
       "1    03-31-44  concrete material - above grade horizontals  \n",
       "2    03-31-44  concrete material - above grade horizontals  \n",
       "3    03-31-44  concrete material - above grade horizontals  \n",
       "4    03-31-44  concrete material - above grade horizontals  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = df_output.merge(name_mapping, left_on='Actual Code',right_on='Cost Code')\n",
    "out.rename(index=str, columns={'Description':'Actual Code Desc.'}, inplace = True)\n",
    "out.drop(['Cost Code'], axis = 1, inplace = True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "      <th>Predicted Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel Surcharge</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuel Surcharge - Applies per load to all concrete</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overtime - Applies to 7:00am and after 5:00pm</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ultra Series Flow1-110mm</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environmental Charge - Per m3 to all concrete</td>\n",
       "      <td>03-31-43</td>\n",
       "      <td>03-31-44</td>\n",
       "      <td>concrete material - above grade horizontals</td>\n",
       "      <td>concrete material - above grade verticals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Predicted Code  \\\n",
       "0                                     Fuel Surcharge       03-31-43   \n",
       "1  Fuel Surcharge - Applies per load to all concrete       03-31-43   \n",
       "2      Overtime - Applies to 7:00am and after 5:00pm       03-31-43   \n",
       "3                           Ultra Series Flow1-110mm       03-31-43   \n",
       "4      Environmental Charge - Per m3 to all concrete       03-31-43   \n",
       "\n",
       "  Actual Code                            Actual Code Desc.  \\\n",
       "0    03-31-44  concrete material - above grade horizontals   \n",
       "1    03-31-44  concrete material - above grade horizontals   \n",
       "2    03-31-44  concrete material - above grade horizontals   \n",
       "3    03-31-44  concrete material - above grade horizontals   \n",
       "4    03-31-44  concrete material - above grade horizontals   \n",
       "\n",
       "                        Predicted Code Desc.  \n",
       "0  concrete material - above grade verticals  \n",
       "1  concrete material - above grade verticals  \n",
       "2  concrete material - above grade verticals  \n",
       "3  concrete material - above grade verticals  \n",
       "4  concrete material - above grade verticals  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.merge(name_mapping, left_on='Predicted Code',right_on='Cost Code')\n",
    "out.drop(['Cost Code'], axis = 1, inplace=True)\n",
    "out.rename(index=str, columns={'Description':'Predicted Code Desc.'}, inplace=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Text', 'Predicted Code','Predicted Code Desc.', 'Actual Code', 'Actual Code Desc.']\n",
    "out = out[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Code</th>\n",
       "      <th>Predicted Code Desc.</th>\n",
       "      <th>Actual Code</th>\n",
       "      <th>Actual Code Desc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>Susan Sebit</td>\n",
       "      <td>01-74-13</td>\n",
       "      <td>progressive clean-up</td>\n",
       "      <td>01-74-13</td>\n",
       "      <td>progressive clean-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>Pick Up Charge</td>\n",
       "      <td>31-23-19</td>\n",
       "      <td>dewatering</td>\n",
       "      <td>01-51-13</td>\n",
       "      <td>temporary power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>Weathermix Concrete - Cold Weather Concrete</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "      <td>03-31-41</td>\n",
       "      <td>concrete material - below-grade verticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>D. Foley</td>\n",
       "      <td>01-74-13</td>\n",
       "      <td>progressive clean-up</td>\n",
       "      <td>01-74-13</td>\n",
       "      <td>progressive clean-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>delivery</td>\n",
       "      <td>01-52-23</td>\n",
       "      <td>field supplies</td>\n",
       "      <td>31-23-23</td>\n",
       "      <td>import fill to slab base</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Text Predicted Code  \\\n",
       "3982                                  Susan Sebit       01-74-13   \n",
       "4377                               Pick Up Charge       31-23-19   \n",
       "1968  Weathermix Concrete - Cold Weather Concrete       03-31-41   \n",
       "3951                                     D. Foley       01-74-13   \n",
       "3341                                     delivery       01-52-23   \n",
       "\n",
       "                           Predicted Code Desc. Actual Code  \\\n",
       "3982                       progressive clean-up    01-74-13   \n",
       "4377                                 dewatering    01-51-13   \n",
       "1968  concrete material - below-grade verticals    03-31-41   \n",
       "3951                       progressive clean-up    01-74-13   \n",
       "3341                             field supplies    31-23-23   \n",
       "\n",
       "                              Actual Code Desc.  \n",
       "3982                       progressive clean-up  \n",
       "4377                            temporary power  \n",
       "1968  concrete material - below-grade verticals  \n",
       "3951                       progressive clean-up  \n",
       "3341                   import fill to slab base  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
